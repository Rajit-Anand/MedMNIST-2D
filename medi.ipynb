{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from medmnist import INFO  # Contains dataset metadata\n",
    "import medmnist          # This imports all available MedMNIST dataset classes\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Convolutional-KANs'...\n",
      "remote: Enumerating objects: 2379, done.\u001b[K\n",
      "remote: Counting objects: 100% (409/409), done.\u001b[K\n",
      "remote: Compressing objects: 100% (209/209), done.\u001b[K\n",
      "remote: Total 2379 (delta 266), reused 311 (delta 196), pack-reused 1970 (from 1)\u001b[K\n",
      "Receiving objects: 100% (2379/2379), 45.65 MiB | 797.00 KiB/s, done.\n",
      "Resolving deltas: 100% (1286/1286), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/AntonioTepsich/Convolutional-KANs.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/home/Documents/pytorch-test/Convolutional-KANs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd Convolutional-KANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib==3.6.2 (from -r requirements.txt (line 1))\n",
      "  Downloading matplotlib-3.6.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: numpy==1.26.4 in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
      "Collecting pandas==2.2.2 (from -r requirements.txt (line 3))\n",
      "  Downloading pandas-2.2.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting scikit-learn==1.4.2 (from -r requirements.txt (line 4))\n",
      "  Downloading scikit_learn-1.4.2-cp311-cp311-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting tqdm==4.66.4 (from -r requirements.txt (line 5))\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting torch==2.3.0 (from -r requirements.txt (line 6))\n",
      "  Downloading torch-2.3.0-cp311-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Collecting torchvision==0.18.0 (from -r requirements.txt (line 7))\n",
      "  Downloading torchvision-0.18.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting pyprof (from -r requirements.txt (line 8))\n",
      "  Downloading pyprof-1.0.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from matplotlib==3.6.2->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from matplotlib==3.6.2->-r requirements.txt (line 1)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from matplotlib==3.6.2->-r requirements.txt (line 1)) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from matplotlib==3.6.2->-r requirements.txt (line 1)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from matplotlib==3.6.2->-r requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from matplotlib==3.6.2->-r requirements.txt (line 1)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from matplotlib==3.6.2->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from matplotlib==3.6.2->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from pandas==2.2.2->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from pandas==2.2.2->-r requirements.txt (line 3)) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from scikit-learn==1.4.2->-r requirements.txt (line 4)) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from scikit-learn==1.4.2->-r requirements.txt (line 4)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from scikit-learn==1.4.2->-r requirements.txt (line 4)) (3.5.0)\n",
      "Requirement already satisfied: filelock in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from torch==2.3.0->-r requirements.txt (line 6)) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from torch==2.3.0->-r requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from torch==2.3.0->-r requirements.txt (line 6)) (1.13.1)\n",
      "Requirement already satisfied: networkx in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from torch==2.3.0->-r requirements.txt (line 6)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from torch==2.3.0->-r requirements.txt (line 6)) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from torch==2.3.0->-r requirements.txt (line 6)) (2024.12.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib==3.6.2->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from jinja2->torch==2.3.0->-r requirements.txt (line 6)) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages (from sympy->torch==2.3.0->-r requirements.txt (line 6)) (1.3.0)\n",
      "Downloading matplotlib-3.6.2-cp311-cp311-macosx_11_0_arm64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.2-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.4.2-cp311-cp311-macosx_12_0_arm64.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Downloading torch-2.3.0-cp311-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.18.0-cp311-cp311-macosx_11_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyprof-1.0.0-py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: tqdm, pyprof, torch, scikit-learn, pandas, matplotlib, torchvision\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.6.0\n",
      "    Uninstalling torch-2.6.0:\n",
      "      Successfully uninstalled torch-2.6.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.6.1\n",
      "    Uninstalling scikit-learn-1.6.1:\n",
      "      Successfully uninstalled scikit-learn-1.6.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.3\n",
      "    Uninstalling pandas-2.2.3:\n",
      "      Successfully uninstalled pandas-2.2.3\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.10.0\n",
      "    Uninstalling matplotlib-3.10.0:\n",
      "      Successfully uninstalled matplotlib-3.10.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.21.0\n",
      "    Uninstalling torchvision-0.21.0:\n",
      "      Successfully uninstalled torchvision-0.21.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.6.0 requires torch==2.6.0, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed matplotlib-3.6.2 pandas-2.2.2 pyprof-1.0.0 scikit-learn-1.4.2 torch-2.3.0 torchvision-0.18.0 tqdm-4.66.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from architectures_28x28.CKAN_BN import CKAN_BN\n",
    "from architectures_28x28.SimpleModels import *\n",
    "from architectures_28x28.ConvNet import ConvNet\n",
    "from architectures_28x28.KANConvs_MLP import KANC_MLP\n",
    "from architectures_28x28.KKAN import KKAN_Convolutional_Network\n",
    "from architectures_28x28.conv_and_kan import NormalConvsKAN\n",
    "from kan_convolutional.KANConv import KAN_Convolutional_Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image  # Import PIL's Image module\n",
    "\n",
    "class MyMedNISTDataset(Dataset):\n",
    "    def __init__(self, npz_path, split='train', transform=None):\n",
    "        super().__init__()\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Load data from .npz using NumPy\n",
    "        data_dict = np.load(npz_path)\n",
    "        \n",
    "        # Based on the chosen split, pick the corresponding arrays\n",
    "        if split == 'train':\n",
    "            self.images = data_dict['train_images']\n",
    "            self.labels = data_dict['train_labels']\n",
    "        elif split == 'val':\n",
    "            self.images = data_dict['val_images']\n",
    "            self.labels = data_dict['val_labels']\n",
    "        elif split == 'test':\n",
    "            self.images = data_dict['test_images']\n",
    "            self.labels = data_dict['test_labels']\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown split: {split} (expected 'train', 'val', or 'test')\")\n",
    "        \n",
    "        # Convert labels to a 1D array if necessary\n",
    "        self.labels = np.squeeze(self.labels)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Convert image to float32 if needed\n",
    "        image = image.astype(np.float32)\n",
    "        \n",
    "        # Convert NumPy array to PIL Image.\n",
    "        # Note: Depending on your data's value range, you might need to adjust this.\n",
    "        # For example, if your data is already in [0, 255] you can convert directly.\n",
    "        # If it's in [0, 1], consider scaling by 255 first.\n",
    "        image = Image.fromarray(np.uint8(image))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(n_channels):\n",
    "    # If not 3 channels, first convert to 3 channels; otherwise, use identity.\n",
    "    convert = transforms.Grayscale(num_output_channels=3) if n_channels != 3 else lambda x: x\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        convert,\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.1),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.1),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                             std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        convert,\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                             std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    val_transform = test_transform\n",
    "\n",
    "    return train_transform, val_transform, test_transform\n",
    "\n",
    "# EXAMPLE USAGE\n",
    "# for key in dataset_keys:\n",
    "#     info = INFO[key]\n",
    "#     n_channels = info.get('n_channels', 1)\n",
    "#     npz_path = f\"./data/{key}.npz\"\n",
    "#     train_dataset = MyMedNISTDataset(\n",
    "#         npz_path=npz_path,\n",
    "#         split='train',\n",
    "#         transform=get_transforms(n_channels)[0]\n",
    "#     )\n",
    "#     print(f\"Train {key} size:\", len(train_dataset))\n",
    "\n",
    "# Create a DataLoader to batch and shuffle\n",
    "#train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying diff architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# class conv_block(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, **kwargs):\n",
    "#         super(conv_block, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "#         self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         # Use functional ReLU (non-inplace by default)\n",
    "#         x = F.relu(self.batchnorm(self.conv1(x)))\n",
    "#         return x\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# A helper block that performs Conv -> BatchNorm -> ReLU.\n",
    "def conv_block(in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "                  stride=stride, padding=padding, bias=False),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "# A helper block that omits the ReLU activation (used for the final conv and shortcut).\n",
    "def conv_block_no_act(in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "                  stride=stride, padding=padding, bias=False),\n",
    "        nn.BatchNorm2d(out_channels)\n",
    "    )\n",
    "\n",
    "class ResBlock50(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, expansion=4):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Desired number of output channels.\n",
    "                                Must be divisible by 'expansion'.\n",
    "            stride (int): Stride for the 3x3 convolution (for spatial downsampling).\n",
    "            expansion (int): Expansion factor to compute the bottleneck channels.\n",
    "                             For ResNet-50, this is typically 4.\n",
    "        \"\"\"\n",
    "        super(ResBlock50, self).__init__()\n",
    "        \n",
    "        # Compute the bottleneck (intermediate) channel count.\n",
    "        bottleneck_channels = out_channels // expansion\n",
    "        \n",
    "        # First 1x1 convolution: reduce dimensions.\n",
    "        self.conv1 = conv_block(in_channels, bottleneck_channels, kernel_size=1, stride=1, padding=0)\n",
    "        # 3x3 convolution: spatial processing (with possible downsampling).\n",
    "        self.conv2 = conv_block(bottleneck_channels, bottleneck_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        # Final 1x1 convolution: expand dimensions. No ReLU here.\n",
    "        self.conv3 = conv_block_no_act(bottleneck_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        # Shortcut path: if dimensions differ (either spatially or in channel depth),\n",
    "        # use a 1x1 convolution to match the dimensions.\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = conv_block_no_act(in_channels, out_channels, kernel_size=1, stride=stride, padding=0)\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        \n",
    "        # Out-of-place addition for the residual connection.\n",
    "        out = torch.add(out, identity)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class inception_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, out_1x1_pool):\n",
    "        super(inception_block, self).__init__()\n",
    "        self.branch1 = conv_block(in_channels, out_1x1, kernel_size=1)\n",
    "        self.branch2 = nn.Sequential(\n",
    "            conv_block(in_channels, red_3x3, kernel_size=1),\n",
    "            conv_block(red_3x3, out_3x3, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            conv_block(in_channels, out_1x1_pool, kernel_size=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        outputs = [branch1, branch2, branch3]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "class ResBlock18(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlock18, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        # Second convolution: always stride=1, keeps spatial dimensions same\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Shortcut connection: if input and output dimensions differ, adjust using 1x1 convolution\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x  # Save input for the residual connection\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        # Adjust dimensions if necessary\n",
    "        identity = self.shortcut(id)\n",
    "        \n",
    "        x += identity  # Residual addition\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# -----------------------------------------\n",
    "# Define a Basic Residual Block\n",
    "# -----------------------------------------\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple residual block with two 3x3 convolutional layers.\n",
    "    If the input and output dimensions differ (in channels or spatial size),\n",
    "    a 1x1 convolution is applied in the shortcut connection.\n",
    "    \"\"\"\n",
    "    expansion = 1  # For BasicBlock, the output channels equal out_channels.\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        # First convolution: may use stride > 1 for downsampling.\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        # Second convolution: always stride 1.\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Define the shortcut connection.\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            # Use a 1x1 convolution to match dimensions.\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
    "                          stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = torch.add(out, identity)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "# -----------------------------------------\n",
    "# MiniResNet with 12 Weighted Layers\n",
    "# -----------------------------------------\n",
    "class MiniResNet12(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MiniResNet12, self).__init__()\n",
    "        # Initial convolution: from 3 channels to 32 channels.\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Five residual blocks.\n",
    "        # Block 1: 32 -> 32 channels; no downsampling (28x28 remains).\n",
    "        self.layer1 = BasicBlock(32, 32, stride=1)\n",
    "        # Block 2: 32 -> 64 channels; downsample spatially (28x28 -> 14x14).\n",
    "        self.layer2 = BasicBlock(32, 64, stride=2)\n",
    "        # Block 3: 64 -> 128 channels; downsample spatially (14x14 -> 7x7).\n",
    "        self.layer3 = BasicBlock(64, 128, stride=2)\n",
    "        # Block 4: 128 -> 128 channels; no further downsampling.\n",
    "        self.layer4 = BasicBlock(128, 128, stride=1)\n",
    "        # Block 5: 128 -> 128 channels; no downsampling.\n",
    "        self.layer5 = BasicBlock(128, 128, stride=1)\n",
    "        \n",
    "        # Global average pooling reduces spatial dimensions to 1x1.\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # Final fully connected layer: 128 -> num_classes.\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initial convolution and activation.\n",
    "        out = F.relu(self.bn1(self.conv1(x)))  # Shape: (B, 32, 28, 28)\n",
    "        # Residual blocks:\n",
    "        out = self.layer1(out)  # (B, 32, 28, 28)\n",
    "        out = self.layer2(out)  # (B, 64, 14, 14)\n",
    "        out = self.layer3(out)  # (B, 128, 7, 7)\n",
    "        out = self.layer4(out)  # (B, 128, 7, 7)\n",
    "        out = self.layer5(out)  # (B, 128, 7, 7)\n",
    "        # Global average pooling.\n",
    "        out = self.avgpool(out)  # (B, 128, 1, 1)\n",
    "        out = torch.flatten(out, 1)  # (B, 128)\n",
    "        out = self.fc(out)  # (B, num_classes)\n",
    "        return out\n",
    "\n",
    "# -----------------------------------------\n",
    "# Testing the MiniResNet12\n",
    "# -----------------------------------------\n",
    "if __name__ == '__main__':\n",
    "    model = MiniResNet12(num_classes=10)\n",
    "    x = torch.randn(1, 3, 28, 28)\n",
    "    y = model(x)\n",
    "    print(\"Output shape:\", y.shape)  # Expected: [1, 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# -----------------------------------------\n",
    "# Define a Basic Residual Block\n",
    "# -----------------------------------------\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple residual block with two 3x3 convolutional layers.\n",
    "    If the input and output dimensions differ (in channels or spatial size),\n",
    "    a 1x1 convolution is applied in the shortcut connection.\n",
    "    \"\"\"\n",
    "    expansion = 1  # For BasicBlock, the output channels equal out_channels.\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        # First convolution: may use stride > 1 for downsampling.\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        # Second convolution: always stride 1.\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Define the shortcut connection.\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            # Use a 1x1 convolution to match dimensions.\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
    "                          stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = torch.add(out, identity)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "# -----------------------------------------\n",
    "# MiniResNet with 12 Weighted Layers\n",
    "# -----------------------------------------\n",
    "class MiniResNet12_2(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MiniResNet12_2, self).__init__()\n",
    "        # Initial convolution: from 3 channels to 32 channels.\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Five residual blocks.\n",
    "        # Block 1: 32 -> 32 channels; no downsampling (28x28 remains).\n",
    "        self.layer1 = BasicBlock(32, 32, stride=1)\n",
    "        # Block 2: 32 -> 64 channels; downsample spatially (28x28 -> 14x14).\n",
    "        self.layer2 = BasicBlock(32, 64, stride=2)\n",
    "        # Block 3: 64 -> 128 channels; downsample spatially (14x14 -> 7x7).\n",
    "        self.layer3 = BasicBlock(64, 128, stride=2)\n",
    "        # Block 4: 128 -> 128 channels; no further downsampling.\n",
    "        self.layer4 = BasicBlock(128, 128, stride=1)\n",
    "        # Block 5: 128 -> 128 channels; no downsampling.\n",
    "        self.layer5 = BasicBlock(128, 128, stride=1)\n",
    "        self.dropout= nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(128*7*7, 128)\n",
    "        # Final fully connected layer: 128 -> num_classes.\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initial convolution and activation.\n",
    "        out = F.relu(self.bn1(self.conv1(x)))  # Shape: (B, 32, 28, 28)\n",
    "        # Residual blocks:\n",
    "        out = self.layer1(out)  # (B, 32, 28, 28)\n",
    "        out = self.layer2(out)  # (B, 64, 14, 14)\n",
    "        out = self.layer3(out)  # (B, 128, 7, 7)\n",
    "        out = self.layer4(out)  # (B, 128, 7, 7)\n",
    "        out = self.layer5(out)  # (B, 128, 7, 7)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.dropout(out)\n",
    "        out = F.relu( self.fc1(out) ) # (B, num_classes)\n",
    "        out = self.fc2(out)  # (B, num_classes)\n",
    "        return out\n",
    "\n",
    "# -----------------------------------------\n",
    "# Testing the MiniResNet12\n",
    "# -----------------------------------------\n",
    "if __name__ == '__main__':\n",
    "    model = MiniResNet12(num_classes=10)\n",
    "    x = torch.randn(1, 3, 28, 28)\n",
    "    y = model(x)\n",
    "    print(\"Output shape:\", y.shape)  # Expected: [1, 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeXtLite(\n",
      "  (stem): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): GELU(approximate='none')\n",
      "  )\n",
      "  (stage1): ConvNeXtBlock(\n",
      "    (dwconv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
      "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    (pwconv1): Linear(in_features=64, out_features=256, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "    (pwconv2): Linear(in_features=256, out_features=64, bias=True)\n",
      "  )\n",
      "  (down1): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (stage2): ConvNeXtBlock(\n",
      "    (dwconv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "    (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  )\n",
      "  (down2): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (stage3): ConvNeXtBlock(\n",
      "    (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "    (act): GELU(approximate='none')\n",
      "    (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  )\n",
      "  (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Output shape: torch.Size([8, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#############################################\n",
    "# ConvNeXt-Inspired Building Block\n",
    "#############################################\n",
    "class ConvNeXtBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A ConvNeXt-inspired block that:\n",
    "      - Applies a depthwise convolution (with a relatively large kernel) to capture spatial context.\n",
    "      - Rearranges the tensor to channel-last and applies LayerNorm.\n",
    "      - Uses two pointwise (1x1) convolutions (implemented as linear layers) with an expansion (MLP)\n",
    "        and a GELU activation in between.\n",
    "      - Adds the original input as a residual connection.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, kernel_size=7, expansion=4):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dim (int): Number of input (and output) channels.\n",
    "            kernel_size (int): Kernel size for the depthwise convolution.\n",
    "            expansion (int): Factor by which to expand the channels in the MLP.\n",
    "        \"\"\"\n",
    "        super(ConvNeXtBlock, self).__init__()\n",
    "        self.dwconv = nn.Conv2d(dim, dim, kernel_size=kernel_size, padding=kernel_size // 2, groups=dim)\n",
    "        # We use LayerNorm in the channel-last format; hence, we will permute dimensions.\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        # Pointwise conv (implemented as a Linear layer) to expand channels.\n",
    "        self.pwconv1 = nn.Linear(dim, expansion * dim)\n",
    "        self.act = nn.GELU()\n",
    "        # Pointwise conv to bring the channels back to the original dimension.\n",
    "        self.pwconv2 = nn.Linear(expansion * dim, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # Save input for the residual connection.\n",
    "        x = self.dwconv(x)  # Depthwise convolution; shape remains (B, dim, H, W).\n",
    "\n",
    "        # Permute to (B, H, W, C) so that LayerNorm works over the channel dimension.\n",
    "        x = x.permute(0, 2, 3, 1)  \n",
    "        x = self.norm(x)\n",
    "        # Apply the first pointwise convolution (expansion) followed by GELU.\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        # Apply the second pointwise convolution (projection back to dim channels).\n",
    "        x = self.pwconv2(x)\n",
    "        # Permute back to (B, C, H, W).\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        # Residual connection.\n",
    "        return x + residual\n",
    "\n",
    "#############################################\n",
    "# Overall Model\n",
    "#############################################\n",
    "class ConvNeXtLite(nn.Module):\n",
    "    \"\"\"\n",
    "    A ConvNeXt-inspired architecture with roughly 12 convolutional layers.\n",
    "    \n",
    "    The network comprises:\n",
    "      - A stem convolution that downsamples the input.\n",
    "      - Three stages, each consisting of one ConvNeXt block.\n",
    "      - Two downsampling layers (strided convolutions) placed between stages.\n",
    "      - A classification head with adaptive pooling and a fully-connected layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10, in_channels=3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes (int): Number of output classes.\n",
    "            in_channels (int): Number of input image channels (3 for RGB, 1 for grayscale).\n",
    "        \"\"\"\n",
    "        super(ConvNeXtLite, self).__init__()\n",
    "        # Define channel dimensions for each stage.\n",
    "        dims = [64, 128, 256]\n",
    "        \n",
    "        # Stem: patchify the input.\n",
    "        # Using a 4x4 conv with stride=2: input 28x28 → output 14x14.\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, dims[0], kernel_size=4, stride=2, padding=1),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        # Stage 1: one ConvNeXt block at resolution 14x14.\n",
    "        self.stage1 = ConvNeXtBlock(dim=dims[0], kernel_size=7, expansion=4)\n",
    "        \n",
    "        # Downsample 1: reduce spatial dimensions (14x14 → 7x7) and increase channels.\n",
    "        self.down1 = nn.Conv2d(dims[0], dims[1], kernel_size=2, stride=2)\n",
    "        \n",
    "        # Stage 2: one ConvNeXt block at resolution 7x7.\n",
    "        self.stage2 = ConvNeXtBlock(dim=dims[1], kernel_size=7, expansion=4)\n",
    "        \n",
    "        # Downsample 2: further downsample (7x7 → ~3x3) and increase channels.\n",
    "        self.down2 = nn.Conv2d(dims[1], dims[2], kernel_size=2, stride=2)\n",
    "        \n",
    "        # Stage 3: one ConvNeXt block at the lowest resolution.\n",
    "        self.stage3 = ConvNeXtBlock(dim=dims[2], kernel_size=7, expansion=4)\n",
    "        \n",
    "        # Classification head: global pooling then a fully-connected layer.\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(dims[2], num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (B, in_channels, 28, 28)\n",
    "        x = self.stem(x)    # → (B, 64, 14, 14)\n",
    "        x = self.stage1(x)  # → (B, 64, 14, 14)\n",
    "        x = self.down1(x)   # → (B, 128, 7, 7)\n",
    "        x = self.stage2(x)  # → (B, 128, 7, 7)\n",
    "        x = self.down2(x)   # → (B, 256, ~3, ~3)  (exact size depends on rounding)\n",
    "        x = self.stage3(x)  # → (B, 256, ~3, ~3)\n",
    "        x = self.pool(x)    # → (B, 256, 1, 1)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "#############################################\n",
    "# Testing the Model\n",
    "#############################################\n",
    "if __name__ == '__main__':\n",
    "    model = ConvNeXtLite(num_classes=10, in_channels=3)\n",
    "    print(model)\n",
    "    \n",
    "    # Create a dummy batch of 8 RGB images of size 28x28.\n",
    "    dummy_input = torch.randn(8, 3, 28, 28)\n",
    "    dummy_output = model(dummy_input)\n",
    "    print(\"Output shape:\", dummy_output.shape)  # Expected: (8, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=20, patience=5):\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_f1 = 0\n",
    "    best_val_loss_epoch = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        train_preds = []\n",
    "        train_labels = []\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\", leave=False)\n",
    "        for images, labels in train_pbar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # Calculate batch accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += (preds == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "            # Collect predictions and true labels for F1 score\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            train_pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        train_loss = running_train_loss / len(train_loader.dataset)\n",
    "        train_acc = train_correct / train_total\n",
    "\n",
    "        # Calculate F1 score for training\n",
    "        train_f1 = f1_score(train_labels, train_preds, average='macro')\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "\n",
    "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_pbar:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "                running_val_loss += loss.item() * images.size(0)\n",
    "\n",
    "                # Calculate batch accuracy\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "                # Collect predictions and true labels for F1 score\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                val_pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        # Calculate F1 score for validation\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} -- \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} |\"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} \")\n",
    "        \n",
    "        #Save the best model (lowest validation loss)\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_val_loss_epoch = epoch\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "        # if val_f1 > best_val_f1:\n",
    "        #     best_val_f1 = val_f1\n",
    "        #     best_val_f1_epoch = epoch\n",
    "        #     best_model_state = model.state_dict()\n",
    "\n",
    "        if epoch - best_val_loss_epoch >= patience:\n",
    "            print(f\"Stopping early because validation loss has not improved in {patience} epochs.\")\n",
    "            break\n",
    "\n",
    "        # if epoch - best_val_f1_epoch >= patience:\n",
    "        #     print(f\"Stopping early because validation F1 score has not improved in {patience} epochs.\")\n",
    "        #     break\n",
    "\n",
    "    #print(f\"Best Validation F1: {best_val_f1:.4f}\")\n",
    "    print(f\"Best Validation Loss: {best_val_loss:.4f}\")\n",
    "    model.load_state_dict(best_model_state)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, fbeta_score, confusion_matrix, classification_report)\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "   \n",
    "    model.eval()\n",
    "    running_test_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            running_test_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            # Get predictions (assuming outputs are raw logits)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_loss = running_test_loss / len(test_loader.dataset)\n",
    "    \n",
    "    # Compute metrics using scikit-learn\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    # f2 = fbeta_score(all_labels, all_preds, beta=2, average='weighted')\n",
    "    # cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Accuracy  : {accuracy:.4f}\")\n",
    "    print(f\"Precision : {precision:.4f}\")\n",
    "    print(f\"Recall    : {recall:.4f}\")\n",
    "    print(f\"F1 Score  : {f1:.4f}\")\n",
    "    #print(f\"F2 Score  : {f2:.4f}\")\n",
    "    #print(\"Confusion Matrix:\")\n",
    "    #print(cm)\n",
    "    #print(\"\\nClassification Report:\")\n",
    "    #print(classification_report(all_labels, all_preds))\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "task_classes = {'breastmnist': 2,\n",
    " 'dermamnist': 7,\n",
    " 'octmnist': 4,\n",
    " 'organamnist': 11,\n",
    " 'organcmnist': 11,\n",
    " 'organsmnist': 11,\n",
    " 'pathmnist': 9,\n",
    " 'pneumoniamnist': 2,\n",
    " 'retinamnist': 5,\n",
    " 'tissuemnist': 8,\n",
    " 'bloodmnist': 8}\n",
    "\n",
    "# Set device.\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "dataset_keys = [\n",
    "    'breastmnist',\n",
    "    'dermamnist',\n",
    "    'octmnist',\n",
    "    'organcmnist',\n",
    "    'organsmnist',\n",
    "    'pathmnist',\n",
    "    'pneumoniamnist',\n",
    "    'retinamnist',\n",
    "    'tissuemnist',\n",
    "    'bloodmnist',\n",
    "    'organamnist'\n",
    "]\n",
    "\n",
    "num_epochs = {\n",
    "    'breastmnist': 100,\n",
    "    'dermamnist': 80,\n",
    "    'octmnist': 50,\n",
    "    'organamnist': 80,\n",
    "    'organcmnist': 80,\n",
    "    'organsmnist': 70,\n",
    "    'pathmnist': 50,\n",
    "    'pneumoniamnist': 80,\n",
    "    'retinamnist': 100,\n",
    "    'tissuemnist': 50,\n",
    "    'bloodmnist': 80\n",
    "}\n",
    "batch_size = 64\n",
    "lr= 0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "for key in dataset_keys:\n",
    "    print(f\"======== Training on dataset: {key} ========\")\n",
    "    npz_path = f\"./data/{key}.npz\"\n",
    "    info = INFO[key]\n",
    "    n_channels = info.get('n_channels', 1)\n",
    "    # Get transforms. For this example, we assume images are single-channel.\n",
    "    train_transform, val_transform, test_transform = get_transforms(n_channels)\n",
    "    \n",
    "    # Create dataset splits\n",
    "    train_dataset = MyMedNISTDataset(npz_path=npz_path, split='train', transform=train_transform)\n",
    "    val_dataset   = MyMedNISTDataset(npz_path=npz_path, split='val', transform=val_transform)\n",
    "    test_dataset  = MyMedNISTDataset(npz_path=npz_path, split='test', transform=test_transform)\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Create a new instance of your model\n",
    "    # (Assuming the number of classes is task_classes[key])\n",
    "    model = ConvNeXtLite(num_classes=task_classes[key])\n",
    "    model = model.to(device)\n",
    "    train_labels = train_dataset.labels  \n",
    "    unique, counts = np.unique(train_labels, return_counts=True)\n",
    "    # Inverse frequency weights:\n",
    "    weights = 1.0 / counts\n",
    "    # Normalize weights such that the average weight is 1.\n",
    "    weights = weights / weights.mean()\n",
    "    print(f\"Computed class weights for {key}: {weights}\")\n",
    "    # Create a task-specific loss criterion.\n",
    "    # weight=torch.tensor(weights, dtype=torch.float).to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(weights, dtype=torch.float).to(device))\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Train the model, monitoring validation loss\n",
    "    model = train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=num_epochs[key], patience=25)\n",
    "    \n",
    "    # Once training is complete, evaluate on the test set\n",
    "    _,_,_,macro_f1=evaluate_model(model, test_loader, criterion, device)\n",
    "    macro_f1 = round(macro_f1, 4)\n",
    "    torch.save(model.state_dict(), f\"./ConvNeXtLite/{key}_{macro_f1}.pth\")\n",
    "    # Free up memory for the next dataset\n",
    "    del model, train_dataset, val_dataset, test_dataset, train_loader, val_loader, test_loader\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"-----------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"bloodmnist_0.9284.pth\",\n",
    "    \"breastmnist_0.7442.pth\",\n",
    "    \"dermamnist_0.4811.pth\",\n",
    "    \"octmnist_0.756.pth\",\n",
    "    \"organamnist_0.7176.pth\",\n",
    "    \"organcmnist_0.7441.pth\",\n",
    "    \"organsmnist_0.6958.pth\",\n",
    "    \"pathmnist_0.8475.pth\",\n",
    "    \"pneumoniamnist_0.8491.pth\",\n",
    "    \"retinamnist_0.3343.pth\",\n",
    "    \"tissuemnist_0.5253.pth\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generating test predictions for BREASTMNIST ===\n",
      "\n",
      "=== Generating test predictions for DERMAMNIST ===\n",
      "\n",
      "=== Generating test predictions for OCTMNIST ===\n",
      "\n",
      "=== Generating test predictions for ORGANCMNIST ===\n",
      "\n",
      "=== Generating test predictions for ORGANSMNIST ===\n",
      "\n",
      "=== Generating test predictions for PATHMNIST ===\n",
      "\n",
      "=== Generating test predictions for PNEUMONIAMNIST ===\n",
      "\n",
      "=== Generating test predictions for RETINAMNIST ===\n",
      "\n",
      "=== Generating test predictions for TISSUEMNIST ===\n",
      "\n",
      "=== Generating test predictions for BLOODMNIST ===\n",
      "\n",
      "=== Generating test predictions for ORGANAMNIST ===\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Where you saved the model checkpoints, e.g. \"./ConvNeXtLite/bloodmnist_0.9284.pth\" etc.\n",
    "CHECKPOINT_DIR = \"./ConvNeXtLite/\"\n",
    "\n",
    "submission_entries = []\n",
    "global_id = 0\n",
    "\n",
    "for task in dataset_keys:\n",
    "    print(f\"\\n=== Generating test predictions for {task.upper()} ===\")\n",
    "    \n",
    "    # 1. Instantiate a fresh ConvNeXtLite with the appropriate number of classes\n",
    "    model = ConvNeXtLite(num_classes=task_classes[task])\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 2. Find the checkpoint file you saved for this task\n",
    "    #    If you have a naming pattern such as {task}_{f1_score}.pth you can pick the best one or \n",
    "    #    adapt the filename below to the exact best checkpoint you want to use:\n",
    "    for weights in model_names:\n",
    "        if task in weights:\n",
    "            checkpoint_path = f\"{CHECKPOINT_DIR}/{weights}\"  # or your naming scheme\n",
    "            break\n",
    "    \n",
    "    # 3. Load state dict\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    # 4. Create the test dataset and DataLoader for this task\n",
    "    info = INFO[task]\n",
    "    n_channels = info.get('n_channels', 1)\n",
    "    train_transform, val_transform, test_transform = get_transforms(n_channels)\n",
    "    \n",
    "    test_dataset  = MyMedNISTDataset(\n",
    "        npz_path=f\"./data/{task}.npz\",\n",
    "        split='test', \n",
    "        transform=test_transform\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # 5. Run inference\n",
    "    id_image_in_task = 0  # local per-task index\n",
    "    with torch.no_grad():\n",
    "        for images, _ in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)  # or model(images, task=task) if multi-headed\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            \n",
    "            # 6. Append results to submission list\n",
    "            preds = preds.cpu().numpy()\n",
    "            for pred in preds:\n",
    "                submission_entries.append({\n",
    "                    \"id\": global_id,\n",
    "                    \"id_image_in_task\": id_image_in_task,\n",
    "                    \"task_name\": task,\n",
    "                    \"label\": int(pred)\n",
    "                })\n",
    "                global_id += 1\n",
    "                id_image_in_task += 1\n",
    "\n",
    "    # Clean up memory before moving to the next task\n",
    "    del model, test_dataset, test_loader\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96941"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submission_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0, 'id_image_in_task': 0, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 1, 'id_image_in_task': 1, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 2, 'id_image_in_task': 2, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 3, 'id_image_in_task': 3, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 4, 'id_image_in_task': 4, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 5, 'id_image_in_task': 5, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 6, 'id_image_in_task': 6, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 7, 'id_image_in_task': 7, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 8, 'id_image_in_task': 8, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 9, 'id_image_in_task': 9, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 10, 'id_image_in_task': 10, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 11, 'id_image_in_task': 11, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 12, 'id_image_in_task': 12, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 13, 'id_image_in_task': 13, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 14, 'id_image_in_task': 14, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 15, 'id_image_in_task': 15, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 16, 'id_image_in_task': 16, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 17, 'id_image_in_task': 17, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 18, 'id_image_in_task': 18, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 19, 'id_image_in_task': 19, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 20, 'id_image_in_task': 20, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 21, 'id_image_in_task': 21, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 22, 'id_image_in_task': 22, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 23, 'id_image_in_task': 23, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 24, 'id_image_in_task': 24, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 25, 'id_image_in_task': 25, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 26, 'id_image_in_task': 26, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 27, 'id_image_in_task': 27, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 28, 'id_image_in_task': 28, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 29, 'id_image_in_task': 29, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 30, 'id_image_in_task': 30, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 31, 'id_image_in_task': 31, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 32, 'id_image_in_task': 32, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 33, 'id_image_in_task': 33, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 34, 'id_image_in_task': 34, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 35, 'id_image_in_task': 35, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 36, 'id_image_in_task': 36, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 37, 'id_image_in_task': 37, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 38, 'id_image_in_task': 38, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 39, 'id_image_in_task': 39, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 40, 'id_image_in_task': 40, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 41, 'id_image_in_task': 41, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 42, 'id_image_in_task': 42, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 43, 'id_image_in_task': 43, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 44, 'id_image_in_task': 44, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 45, 'id_image_in_task': 45, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 46, 'id_image_in_task': 46, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 47, 'id_image_in_task': 47, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 48, 'id_image_in_task': 48, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 49, 'id_image_in_task': 49, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 50, 'id_image_in_task': 50, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 51, 'id_image_in_task': 51, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 52, 'id_image_in_task': 52, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 53, 'id_image_in_task': 53, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 54, 'id_image_in_task': 54, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 55, 'id_image_in_task': 55, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 56, 'id_image_in_task': 56, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 57, 'id_image_in_task': 57, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 58, 'id_image_in_task': 58, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 59, 'id_image_in_task': 59, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 60, 'id_image_in_task': 60, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 61, 'id_image_in_task': 61, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 62, 'id_image_in_task': 62, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 63, 'id_image_in_task': 63, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 64, 'id_image_in_task': 64, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 65, 'id_image_in_task': 65, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 66, 'id_image_in_task': 66, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 67, 'id_image_in_task': 67, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 68, 'id_image_in_task': 68, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 69, 'id_image_in_task': 69, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 70, 'id_image_in_task': 70, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 71, 'id_image_in_task': 71, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 72, 'id_image_in_task': 72, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 73, 'id_image_in_task': 73, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 74, 'id_image_in_task': 74, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 75, 'id_image_in_task': 75, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 76, 'id_image_in_task': 76, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 77, 'id_image_in_task': 77, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 78, 'id_image_in_task': 78, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 79, 'id_image_in_task': 79, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 80, 'id_image_in_task': 80, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 81, 'id_image_in_task': 81, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 82, 'id_image_in_task': 82, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 83, 'id_image_in_task': 83, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 84, 'id_image_in_task': 84, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 85, 'id_image_in_task': 85, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 86, 'id_image_in_task': 86, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 87, 'id_image_in_task': 87, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 88, 'id_image_in_task': 88, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 89, 'id_image_in_task': 89, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 90, 'id_image_in_task': 90, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 91, 'id_image_in_task': 91, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 92, 'id_image_in_task': 92, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 93, 'id_image_in_task': 93, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 94, 'id_image_in_task': 94, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 95, 'id_image_in_task': 95, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 96, 'id_image_in_task': 96, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 97, 'id_image_in_task': 97, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 98, 'id_image_in_task': 98, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 99, 'id_image_in_task': 99, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 100, 'id_image_in_task': 100, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 101, 'id_image_in_task': 101, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 102, 'id_image_in_task': 102, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 103, 'id_image_in_task': 103, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 104, 'id_image_in_task': 104, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 105, 'id_image_in_task': 105, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 106, 'id_image_in_task': 106, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 107, 'id_image_in_task': 107, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 108, 'id_image_in_task': 108, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 109, 'id_image_in_task': 109, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 110, 'id_image_in_task': 110, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 111, 'id_image_in_task': 111, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 112, 'id_image_in_task': 112, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 113, 'id_image_in_task': 113, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 114, 'id_image_in_task': 114, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 115, 'id_image_in_task': 115, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 116, 'id_image_in_task': 116, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 117, 'id_image_in_task': 117, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 118, 'id_image_in_task': 118, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 119, 'id_image_in_task': 119, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 120, 'id_image_in_task': 120, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 121, 'id_image_in_task': 121, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 122, 'id_image_in_task': 122, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 123, 'id_image_in_task': 123, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 124, 'id_image_in_task': 124, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 125, 'id_image_in_task': 125, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 126, 'id_image_in_task': 126, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 127, 'id_image_in_task': 127, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 128, 'id_image_in_task': 128, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 129, 'id_image_in_task': 129, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 130, 'id_image_in_task': 130, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 131, 'id_image_in_task': 131, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 132, 'id_image_in_task': 132, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 133, 'id_image_in_task': 133, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 134, 'id_image_in_task': 134, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 135, 'id_image_in_task': 135, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 136, 'id_image_in_task': 136, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 137, 'id_image_in_task': 137, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 138, 'id_image_in_task': 138, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 139, 'id_image_in_task': 139, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 140, 'id_image_in_task': 140, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 141, 'id_image_in_task': 141, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 142, 'id_image_in_task': 142, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 143, 'id_image_in_task': 143, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 144, 'id_image_in_task': 144, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 145, 'id_image_in_task': 145, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 146, 'id_image_in_task': 146, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 147, 'id_image_in_task': 147, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 148, 'id_image_in_task': 148, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 149, 'id_image_in_task': 149, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 150, 'id_image_in_task': 150, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 151, 'id_image_in_task': 151, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 152, 'id_image_in_task': 152, 'task_name': 'breastmnist', 'label': 1},\n",
       " {'id': 153, 'id_image_in_task': 153, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 154, 'id_image_in_task': 154, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 155, 'id_image_in_task': 155, 'task_name': 'breastmnist', 'label': 0},\n",
       " {'id': 156, 'id_image_in_task': 0, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 157, 'id_image_in_task': 1, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 158, 'id_image_in_task': 2, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 159, 'id_image_in_task': 3, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 160, 'id_image_in_task': 4, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 161, 'id_image_in_task': 5, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 162, 'id_image_in_task': 6, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 163, 'id_image_in_task': 7, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 164, 'id_image_in_task': 8, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 165, 'id_image_in_task': 9, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 166, 'id_image_in_task': 10, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 167, 'id_image_in_task': 11, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 168, 'id_image_in_task': 12, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 169, 'id_image_in_task': 13, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 170, 'id_image_in_task': 14, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 171, 'id_image_in_task': 15, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 172, 'id_image_in_task': 16, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 173, 'id_image_in_task': 17, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 174, 'id_image_in_task': 18, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 175, 'id_image_in_task': 19, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 176, 'id_image_in_task': 20, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 177, 'id_image_in_task': 21, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 178, 'id_image_in_task': 22, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 179, 'id_image_in_task': 23, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 180, 'id_image_in_task': 24, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 181, 'id_image_in_task': 25, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 182, 'id_image_in_task': 26, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 183, 'id_image_in_task': 27, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 184, 'id_image_in_task': 28, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 185, 'id_image_in_task': 29, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 186, 'id_image_in_task': 30, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 187, 'id_image_in_task': 31, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 188, 'id_image_in_task': 32, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 189, 'id_image_in_task': 33, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 190, 'id_image_in_task': 34, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 191, 'id_image_in_task': 35, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 192, 'id_image_in_task': 36, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 193, 'id_image_in_task': 37, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 194, 'id_image_in_task': 38, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 195, 'id_image_in_task': 39, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 196, 'id_image_in_task': 40, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 197, 'id_image_in_task': 41, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 198, 'id_image_in_task': 42, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 199, 'id_image_in_task': 43, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 200, 'id_image_in_task': 44, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 201, 'id_image_in_task': 45, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 202, 'id_image_in_task': 46, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 203, 'id_image_in_task': 47, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 204, 'id_image_in_task': 48, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 205, 'id_image_in_task': 49, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 206, 'id_image_in_task': 50, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 207, 'id_image_in_task': 51, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 208, 'id_image_in_task': 52, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 209, 'id_image_in_task': 53, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 210, 'id_image_in_task': 54, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 211, 'id_image_in_task': 55, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 212, 'id_image_in_task': 56, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 213, 'id_image_in_task': 57, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 214, 'id_image_in_task': 58, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 215, 'id_image_in_task': 59, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 216, 'id_image_in_task': 60, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 217, 'id_image_in_task': 61, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 218, 'id_image_in_task': 62, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 219, 'id_image_in_task': 63, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 220, 'id_image_in_task': 64, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 221, 'id_image_in_task': 65, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 222, 'id_image_in_task': 66, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 223, 'id_image_in_task': 67, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 224, 'id_image_in_task': 68, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 225, 'id_image_in_task': 69, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 226, 'id_image_in_task': 70, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 227, 'id_image_in_task': 71, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 228, 'id_image_in_task': 72, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 229, 'id_image_in_task': 73, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 230, 'id_image_in_task': 74, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 231, 'id_image_in_task': 75, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 232, 'id_image_in_task': 76, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 233, 'id_image_in_task': 77, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 234, 'id_image_in_task': 78, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 235, 'id_image_in_task': 79, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 236, 'id_image_in_task': 80, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 237, 'id_image_in_task': 81, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 238, 'id_image_in_task': 82, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 239, 'id_image_in_task': 83, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 240, 'id_image_in_task': 84, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 241, 'id_image_in_task': 85, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 242, 'id_image_in_task': 86, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 243, 'id_image_in_task': 87, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 244, 'id_image_in_task': 88, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 245, 'id_image_in_task': 89, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 246, 'id_image_in_task': 90, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 247, 'id_image_in_task': 91, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 248, 'id_image_in_task': 92, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 249, 'id_image_in_task': 93, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 250, 'id_image_in_task': 94, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 251, 'id_image_in_task': 95, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 252, 'id_image_in_task': 96, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 253, 'id_image_in_task': 97, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 254, 'id_image_in_task': 98, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 255, 'id_image_in_task': 99, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 256, 'id_image_in_task': 100, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 257, 'id_image_in_task': 101, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 258, 'id_image_in_task': 102, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 259, 'id_image_in_task': 103, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 260, 'id_image_in_task': 104, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 261, 'id_image_in_task': 105, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 262, 'id_image_in_task': 106, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 263, 'id_image_in_task': 107, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 264, 'id_image_in_task': 108, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 265, 'id_image_in_task': 109, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 266, 'id_image_in_task': 110, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 267, 'id_image_in_task': 111, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 268, 'id_image_in_task': 112, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 269, 'id_image_in_task': 113, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 270, 'id_image_in_task': 114, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 271, 'id_image_in_task': 115, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 272, 'id_image_in_task': 116, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 273, 'id_image_in_task': 117, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 274, 'id_image_in_task': 118, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 275, 'id_image_in_task': 119, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 276, 'id_image_in_task': 120, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 277, 'id_image_in_task': 121, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 278, 'id_image_in_task': 122, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 279, 'id_image_in_task': 123, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 280, 'id_image_in_task': 124, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 281, 'id_image_in_task': 125, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 282, 'id_image_in_task': 126, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 283, 'id_image_in_task': 127, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 284, 'id_image_in_task': 128, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 285, 'id_image_in_task': 129, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 286, 'id_image_in_task': 130, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 287, 'id_image_in_task': 131, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 288, 'id_image_in_task': 132, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 289, 'id_image_in_task': 133, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 290, 'id_image_in_task': 134, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 291, 'id_image_in_task': 135, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 292, 'id_image_in_task': 136, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 293, 'id_image_in_task': 137, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 294, 'id_image_in_task': 138, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 295, 'id_image_in_task': 139, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 296, 'id_image_in_task': 140, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 297, 'id_image_in_task': 141, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 298, 'id_image_in_task': 142, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 299, 'id_image_in_task': 143, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 300, 'id_image_in_task': 144, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 301, 'id_image_in_task': 145, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 302, 'id_image_in_task': 146, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 303, 'id_image_in_task': 147, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 304, 'id_image_in_task': 148, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 305, 'id_image_in_task': 149, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 306, 'id_image_in_task': 150, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 307, 'id_image_in_task': 151, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 308, 'id_image_in_task': 152, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 309, 'id_image_in_task': 153, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 310, 'id_image_in_task': 154, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 311, 'id_image_in_task': 155, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 312, 'id_image_in_task': 156, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 313, 'id_image_in_task': 157, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 314, 'id_image_in_task': 158, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 315, 'id_image_in_task': 159, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 316, 'id_image_in_task': 160, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 317, 'id_image_in_task': 161, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 318, 'id_image_in_task': 162, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 319, 'id_image_in_task': 163, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 320, 'id_image_in_task': 164, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 321, 'id_image_in_task': 165, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 322, 'id_image_in_task': 166, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 323, 'id_image_in_task': 167, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 324, 'id_image_in_task': 168, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 325, 'id_image_in_task': 169, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 326, 'id_image_in_task': 170, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 327, 'id_image_in_task': 171, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 328, 'id_image_in_task': 172, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 329, 'id_image_in_task': 173, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 330, 'id_image_in_task': 174, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 331, 'id_image_in_task': 175, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 332, 'id_image_in_task': 176, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 333, 'id_image_in_task': 177, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 334, 'id_image_in_task': 178, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 335, 'id_image_in_task': 179, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 336, 'id_image_in_task': 180, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 337, 'id_image_in_task': 181, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 338, 'id_image_in_task': 182, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 339, 'id_image_in_task': 183, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 340, 'id_image_in_task': 184, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 341, 'id_image_in_task': 185, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 342, 'id_image_in_task': 186, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 343, 'id_image_in_task': 187, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 344, 'id_image_in_task': 188, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 345, 'id_image_in_task': 189, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 346, 'id_image_in_task': 190, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 347, 'id_image_in_task': 191, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 348, 'id_image_in_task': 192, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 349, 'id_image_in_task': 193, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 350, 'id_image_in_task': 194, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 351, 'id_image_in_task': 195, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 352, 'id_image_in_task': 196, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 353, 'id_image_in_task': 197, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 354, 'id_image_in_task': 198, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 355, 'id_image_in_task': 199, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 356, 'id_image_in_task': 200, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 357, 'id_image_in_task': 201, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 358, 'id_image_in_task': 202, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 359, 'id_image_in_task': 203, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 360, 'id_image_in_task': 204, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 361, 'id_image_in_task': 205, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 362, 'id_image_in_task': 206, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 363, 'id_image_in_task': 207, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 364, 'id_image_in_task': 208, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 365, 'id_image_in_task': 209, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 366, 'id_image_in_task': 210, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 367, 'id_image_in_task': 211, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 368, 'id_image_in_task': 212, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 369, 'id_image_in_task': 213, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 370, 'id_image_in_task': 214, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 371, 'id_image_in_task': 215, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 372, 'id_image_in_task': 216, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 373, 'id_image_in_task': 217, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 374, 'id_image_in_task': 218, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 375, 'id_image_in_task': 219, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 376, 'id_image_in_task': 220, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 377, 'id_image_in_task': 221, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 378, 'id_image_in_task': 222, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 379, 'id_image_in_task': 223, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 380, 'id_image_in_task': 224, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 381, 'id_image_in_task': 225, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 382, 'id_image_in_task': 226, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 383, 'id_image_in_task': 227, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 384, 'id_image_in_task': 228, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 385, 'id_image_in_task': 229, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 386, 'id_image_in_task': 230, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 387, 'id_image_in_task': 231, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 388, 'id_image_in_task': 232, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 389, 'id_image_in_task': 233, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 390, 'id_image_in_task': 234, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 391, 'id_image_in_task': 235, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 392, 'id_image_in_task': 236, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 393, 'id_image_in_task': 237, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 394, 'id_image_in_task': 238, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 395, 'id_image_in_task': 239, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 396, 'id_image_in_task': 240, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 397, 'id_image_in_task': 241, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 398, 'id_image_in_task': 242, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 399, 'id_image_in_task': 243, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 400, 'id_image_in_task': 244, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 401, 'id_image_in_task': 245, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 402, 'id_image_in_task': 246, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 403, 'id_image_in_task': 247, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 404, 'id_image_in_task': 248, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 405, 'id_image_in_task': 249, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 406, 'id_image_in_task': 250, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 407, 'id_image_in_task': 251, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 408, 'id_image_in_task': 252, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 409, 'id_image_in_task': 253, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 410, 'id_image_in_task': 254, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 411, 'id_image_in_task': 255, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 412, 'id_image_in_task': 256, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 413, 'id_image_in_task': 257, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 414, 'id_image_in_task': 258, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 415, 'id_image_in_task': 259, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 416, 'id_image_in_task': 260, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 417, 'id_image_in_task': 261, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 418, 'id_image_in_task': 262, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 419, 'id_image_in_task': 263, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 420, 'id_image_in_task': 264, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 421, 'id_image_in_task': 265, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 422, 'id_image_in_task': 266, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 423, 'id_image_in_task': 267, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 424, 'id_image_in_task': 268, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 425, 'id_image_in_task': 269, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 426, 'id_image_in_task': 270, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 427, 'id_image_in_task': 271, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 428, 'id_image_in_task': 272, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 429, 'id_image_in_task': 273, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 430, 'id_image_in_task': 274, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 431, 'id_image_in_task': 275, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 432, 'id_image_in_task': 276, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 433, 'id_image_in_task': 277, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 434, 'id_image_in_task': 278, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 435, 'id_image_in_task': 279, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 436, 'id_image_in_task': 280, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 437, 'id_image_in_task': 281, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 438, 'id_image_in_task': 282, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 439, 'id_image_in_task': 283, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 440, 'id_image_in_task': 284, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 441, 'id_image_in_task': 285, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 442, 'id_image_in_task': 286, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 443, 'id_image_in_task': 287, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 444, 'id_image_in_task': 288, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 445, 'id_image_in_task': 289, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 446, 'id_image_in_task': 290, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 447, 'id_image_in_task': 291, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 448, 'id_image_in_task': 292, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 449, 'id_image_in_task': 293, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 450, 'id_image_in_task': 294, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 451, 'id_image_in_task': 295, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 452, 'id_image_in_task': 296, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 453, 'id_image_in_task': 297, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 454, 'id_image_in_task': 298, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 455, 'id_image_in_task': 299, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 456, 'id_image_in_task': 300, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 457, 'id_image_in_task': 301, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 458, 'id_image_in_task': 302, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 459, 'id_image_in_task': 303, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 460, 'id_image_in_task': 304, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 461, 'id_image_in_task': 305, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 462, 'id_image_in_task': 306, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 463, 'id_image_in_task': 307, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 464, 'id_image_in_task': 308, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 465, 'id_image_in_task': 309, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 466, 'id_image_in_task': 310, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 467, 'id_image_in_task': 311, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 468, 'id_image_in_task': 312, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 469, 'id_image_in_task': 313, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 470, 'id_image_in_task': 314, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 471, 'id_image_in_task': 315, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 472, 'id_image_in_task': 316, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 473, 'id_image_in_task': 317, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 474, 'id_image_in_task': 318, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 475, 'id_image_in_task': 319, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 476, 'id_image_in_task': 320, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 477, 'id_image_in_task': 321, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 478, 'id_image_in_task': 322, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 479, 'id_image_in_task': 323, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 480, 'id_image_in_task': 324, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 481, 'id_image_in_task': 325, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 482, 'id_image_in_task': 326, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 483, 'id_image_in_task': 327, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 484, 'id_image_in_task': 328, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 485, 'id_image_in_task': 329, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 486, 'id_image_in_task': 330, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 487, 'id_image_in_task': 331, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 488, 'id_image_in_task': 332, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 489, 'id_image_in_task': 333, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 490, 'id_image_in_task': 334, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 491, 'id_image_in_task': 335, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 492, 'id_image_in_task': 336, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 493, 'id_image_in_task': 337, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 494, 'id_image_in_task': 338, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 495, 'id_image_in_task': 339, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 496, 'id_image_in_task': 340, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 497, 'id_image_in_task': 341, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 498, 'id_image_in_task': 342, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 499, 'id_image_in_task': 343, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 500, 'id_image_in_task': 344, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 501, 'id_image_in_task': 345, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 502, 'id_image_in_task': 346, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 503, 'id_image_in_task': 347, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 504, 'id_image_in_task': 348, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 505, 'id_image_in_task': 349, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 506, 'id_image_in_task': 350, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 507, 'id_image_in_task': 351, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 508, 'id_image_in_task': 352, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 509, 'id_image_in_task': 353, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 510, 'id_image_in_task': 354, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 511, 'id_image_in_task': 355, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 512, 'id_image_in_task': 356, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 513, 'id_image_in_task': 357, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 514, 'id_image_in_task': 358, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 515, 'id_image_in_task': 359, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 516, 'id_image_in_task': 360, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 517, 'id_image_in_task': 361, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 518, 'id_image_in_task': 362, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 519, 'id_image_in_task': 363, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 520, 'id_image_in_task': 364, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 521, 'id_image_in_task': 365, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 522, 'id_image_in_task': 366, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 523, 'id_image_in_task': 367, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 524, 'id_image_in_task': 368, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 525, 'id_image_in_task': 369, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 526, 'id_image_in_task': 370, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 527, 'id_image_in_task': 371, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 528, 'id_image_in_task': 372, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 529, 'id_image_in_task': 373, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 530, 'id_image_in_task': 374, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 531, 'id_image_in_task': 375, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 532, 'id_image_in_task': 376, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 533, 'id_image_in_task': 377, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 534, 'id_image_in_task': 378, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 535, 'id_image_in_task': 379, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 536, 'id_image_in_task': 380, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 537, 'id_image_in_task': 381, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 538, 'id_image_in_task': 382, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 539, 'id_image_in_task': 383, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 540, 'id_image_in_task': 384, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 541, 'id_image_in_task': 385, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 542, 'id_image_in_task': 386, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 543, 'id_image_in_task': 387, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 544, 'id_image_in_task': 388, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 545, 'id_image_in_task': 389, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 546, 'id_image_in_task': 390, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 547, 'id_image_in_task': 391, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 548, 'id_image_in_task': 392, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 549, 'id_image_in_task': 393, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 550, 'id_image_in_task': 394, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 551, 'id_image_in_task': 395, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 552, 'id_image_in_task': 396, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 553, 'id_image_in_task': 397, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 554, 'id_image_in_task': 398, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 555, 'id_image_in_task': 399, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 556, 'id_image_in_task': 400, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 557, 'id_image_in_task': 401, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 558, 'id_image_in_task': 402, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 559, 'id_image_in_task': 403, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 560, 'id_image_in_task': 404, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 561, 'id_image_in_task': 405, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 562, 'id_image_in_task': 406, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 563, 'id_image_in_task': 407, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 564, 'id_image_in_task': 408, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 565, 'id_image_in_task': 409, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 566, 'id_image_in_task': 410, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 567, 'id_image_in_task': 411, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 568, 'id_image_in_task': 412, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 569, 'id_image_in_task': 413, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 570, 'id_image_in_task': 414, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 571, 'id_image_in_task': 415, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 572, 'id_image_in_task': 416, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 573, 'id_image_in_task': 417, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 574, 'id_image_in_task': 418, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 575, 'id_image_in_task': 419, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 576, 'id_image_in_task': 420, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 577, 'id_image_in_task': 421, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 578, 'id_image_in_task': 422, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 579, 'id_image_in_task': 423, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 580, 'id_image_in_task': 424, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 581, 'id_image_in_task': 425, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 582, 'id_image_in_task': 426, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 583, 'id_image_in_task': 427, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 584, 'id_image_in_task': 428, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 585, 'id_image_in_task': 429, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 586, 'id_image_in_task': 430, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 587, 'id_image_in_task': 431, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 588, 'id_image_in_task': 432, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 589, 'id_image_in_task': 433, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 590, 'id_image_in_task': 434, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 591, 'id_image_in_task': 435, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 592, 'id_image_in_task': 436, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 593, 'id_image_in_task': 437, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 594, 'id_image_in_task': 438, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 595, 'id_image_in_task': 439, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 596, 'id_image_in_task': 440, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 597, 'id_image_in_task': 441, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 598, 'id_image_in_task': 442, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 599, 'id_image_in_task': 443, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 600, 'id_image_in_task': 444, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 601, 'id_image_in_task': 445, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 602, 'id_image_in_task': 446, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 603, 'id_image_in_task': 447, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 604, 'id_image_in_task': 448, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 605, 'id_image_in_task': 449, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 606, 'id_image_in_task': 450, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 607, 'id_image_in_task': 451, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 608, 'id_image_in_task': 452, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 609, 'id_image_in_task': 453, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 610, 'id_image_in_task': 454, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 611, 'id_image_in_task': 455, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 612, 'id_image_in_task': 456, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 613, 'id_image_in_task': 457, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 614, 'id_image_in_task': 458, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 615, 'id_image_in_task': 459, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 616, 'id_image_in_task': 460, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 617, 'id_image_in_task': 461, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 618, 'id_image_in_task': 462, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 619, 'id_image_in_task': 463, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 620, 'id_image_in_task': 464, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 621, 'id_image_in_task': 465, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 622, 'id_image_in_task': 466, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 623, 'id_image_in_task': 467, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 624, 'id_image_in_task': 468, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 625, 'id_image_in_task': 469, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 626, 'id_image_in_task': 470, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 627, 'id_image_in_task': 471, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 628, 'id_image_in_task': 472, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 629, 'id_image_in_task': 473, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 630, 'id_image_in_task': 474, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 631, 'id_image_in_task': 475, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 632, 'id_image_in_task': 476, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 633, 'id_image_in_task': 477, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 634, 'id_image_in_task': 478, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 635, 'id_image_in_task': 479, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 636, 'id_image_in_task': 480, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 637, 'id_image_in_task': 481, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 638, 'id_image_in_task': 482, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 639, 'id_image_in_task': 483, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 640, 'id_image_in_task': 484, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 641, 'id_image_in_task': 485, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 642, 'id_image_in_task': 486, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 643, 'id_image_in_task': 487, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 644, 'id_image_in_task': 488, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 645, 'id_image_in_task': 489, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 646, 'id_image_in_task': 490, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 647, 'id_image_in_task': 491, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 648, 'id_image_in_task': 492, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 649, 'id_image_in_task': 493, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 650, 'id_image_in_task': 494, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 651, 'id_image_in_task': 495, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 652, 'id_image_in_task': 496, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 653, 'id_image_in_task': 497, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 654, 'id_image_in_task': 498, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 655, 'id_image_in_task': 499, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 656, 'id_image_in_task': 500, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 657, 'id_image_in_task': 501, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 658, 'id_image_in_task': 502, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 659, 'id_image_in_task': 503, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 660, 'id_image_in_task': 504, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 661, 'id_image_in_task': 505, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 662, 'id_image_in_task': 506, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 663, 'id_image_in_task': 507, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 664, 'id_image_in_task': 508, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 665, 'id_image_in_task': 509, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 666, 'id_image_in_task': 510, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 667, 'id_image_in_task': 511, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 668, 'id_image_in_task': 512, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 669, 'id_image_in_task': 513, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 670, 'id_image_in_task': 514, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 671, 'id_image_in_task': 515, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 672, 'id_image_in_task': 516, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 673, 'id_image_in_task': 517, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 674, 'id_image_in_task': 518, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 675, 'id_image_in_task': 519, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 676, 'id_image_in_task': 520, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 677, 'id_image_in_task': 521, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 678, 'id_image_in_task': 522, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 679, 'id_image_in_task': 523, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 680, 'id_image_in_task': 524, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 681, 'id_image_in_task': 525, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 682, 'id_image_in_task': 526, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 683, 'id_image_in_task': 527, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 684, 'id_image_in_task': 528, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 685, 'id_image_in_task': 529, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 686, 'id_image_in_task': 530, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 687, 'id_image_in_task': 531, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 688, 'id_image_in_task': 532, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 689, 'id_image_in_task': 533, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 690, 'id_image_in_task': 534, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 691, 'id_image_in_task': 535, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 692, 'id_image_in_task': 536, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 693, 'id_image_in_task': 537, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 694, 'id_image_in_task': 538, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 695, 'id_image_in_task': 539, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 696, 'id_image_in_task': 540, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 697, 'id_image_in_task': 541, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 698, 'id_image_in_task': 542, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 699, 'id_image_in_task': 543, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 700, 'id_image_in_task': 544, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 701, 'id_image_in_task': 545, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 702, 'id_image_in_task': 546, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 703, 'id_image_in_task': 547, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 704, 'id_image_in_task': 548, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 705, 'id_image_in_task': 549, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 706, 'id_image_in_task': 550, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 707, 'id_image_in_task': 551, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 708, 'id_image_in_task': 552, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 709, 'id_image_in_task': 553, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 710, 'id_image_in_task': 554, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 711, 'id_image_in_task': 555, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 712, 'id_image_in_task': 556, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 713, 'id_image_in_task': 557, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 714, 'id_image_in_task': 558, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 715, 'id_image_in_task': 559, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 716, 'id_image_in_task': 560, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 717, 'id_image_in_task': 561, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 718, 'id_image_in_task': 562, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 719, 'id_image_in_task': 563, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 720, 'id_image_in_task': 564, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 721, 'id_image_in_task': 565, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 722, 'id_image_in_task': 566, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 723, 'id_image_in_task': 567, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 724, 'id_image_in_task': 568, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 725, 'id_image_in_task': 569, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 726, 'id_image_in_task': 570, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 727, 'id_image_in_task': 571, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 728, 'id_image_in_task': 572, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 729, 'id_image_in_task': 573, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 730, 'id_image_in_task': 574, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 731, 'id_image_in_task': 575, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 732, 'id_image_in_task': 576, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 733, 'id_image_in_task': 577, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 734, 'id_image_in_task': 578, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 735, 'id_image_in_task': 579, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 736, 'id_image_in_task': 580, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 737, 'id_image_in_task': 581, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 738, 'id_image_in_task': 582, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 739, 'id_image_in_task': 583, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 740, 'id_image_in_task': 584, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 741, 'id_image_in_task': 585, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 742, 'id_image_in_task': 586, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 743, 'id_image_in_task': 587, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 744, 'id_image_in_task': 588, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 745, 'id_image_in_task': 589, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 746, 'id_image_in_task': 590, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 747, 'id_image_in_task': 591, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 748, 'id_image_in_task': 592, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 749, 'id_image_in_task': 593, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 750, 'id_image_in_task': 594, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 751, 'id_image_in_task': 595, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 752, 'id_image_in_task': 596, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 753, 'id_image_in_task': 597, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 754, 'id_image_in_task': 598, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 755, 'id_image_in_task': 599, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 756, 'id_image_in_task': 600, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 757, 'id_image_in_task': 601, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 758, 'id_image_in_task': 602, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 759, 'id_image_in_task': 603, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 760, 'id_image_in_task': 604, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 761, 'id_image_in_task': 605, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 762, 'id_image_in_task': 606, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 763, 'id_image_in_task': 607, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 764, 'id_image_in_task': 608, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 765, 'id_image_in_task': 609, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 766, 'id_image_in_task': 610, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 767, 'id_image_in_task': 611, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 768, 'id_image_in_task': 612, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 769, 'id_image_in_task': 613, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 770, 'id_image_in_task': 614, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 771, 'id_image_in_task': 615, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 772, 'id_image_in_task': 616, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 773, 'id_image_in_task': 617, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 774, 'id_image_in_task': 618, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 775, 'id_image_in_task': 619, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 776, 'id_image_in_task': 620, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 777, 'id_image_in_task': 621, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 778, 'id_image_in_task': 622, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 779, 'id_image_in_task': 623, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 780, 'id_image_in_task': 624, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 781, 'id_image_in_task': 625, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 782, 'id_image_in_task': 626, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 783, 'id_image_in_task': 627, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 784, 'id_image_in_task': 628, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 785, 'id_image_in_task': 629, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 786, 'id_image_in_task': 630, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 787, 'id_image_in_task': 631, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 788, 'id_image_in_task': 632, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 789, 'id_image_in_task': 633, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 790, 'id_image_in_task': 634, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 791, 'id_image_in_task': 635, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 792, 'id_image_in_task': 636, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 793, 'id_image_in_task': 637, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 794, 'id_image_in_task': 638, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 795, 'id_image_in_task': 639, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 796, 'id_image_in_task': 640, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 797, 'id_image_in_task': 641, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 798, 'id_image_in_task': 642, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 799, 'id_image_in_task': 643, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 800, 'id_image_in_task': 644, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 801, 'id_image_in_task': 645, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 802, 'id_image_in_task': 646, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 803, 'id_image_in_task': 647, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 804, 'id_image_in_task': 648, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 805, 'id_image_in_task': 649, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 806, 'id_image_in_task': 650, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 807, 'id_image_in_task': 651, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 808, 'id_image_in_task': 652, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 809, 'id_image_in_task': 653, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 810, 'id_image_in_task': 654, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 811, 'id_image_in_task': 655, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 812, 'id_image_in_task': 656, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 813, 'id_image_in_task': 657, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 814, 'id_image_in_task': 658, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 815, 'id_image_in_task': 659, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 816, 'id_image_in_task': 660, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 817, 'id_image_in_task': 661, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 818, 'id_image_in_task': 662, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 819, 'id_image_in_task': 663, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 820, 'id_image_in_task': 664, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 821, 'id_image_in_task': 665, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 822, 'id_image_in_task': 666, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 823, 'id_image_in_task': 667, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 824, 'id_image_in_task': 668, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 825, 'id_image_in_task': 669, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 826, 'id_image_in_task': 670, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 827, 'id_image_in_task': 671, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 828, 'id_image_in_task': 672, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 829, 'id_image_in_task': 673, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 830, 'id_image_in_task': 674, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 831, 'id_image_in_task': 675, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 832, 'id_image_in_task': 676, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 833, 'id_image_in_task': 677, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 834, 'id_image_in_task': 678, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 835, 'id_image_in_task': 679, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 836, 'id_image_in_task': 680, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 837, 'id_image_in_task': 681, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 838, 'id_image_in_task': 682, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 839, 'id_image_in_task': 683, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 840, 'id_image_in_task': 684, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 841, 'id_image_in_task': 685, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 842, 'id_image_in_task': 686, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 843, 'id_image_in_task': 687, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 844, 'id_image_in_task': 688, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 845, 'id_image_in_task': 689, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 846, 'id_image_in_task': 690, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 847, 'id_image_in_task': 691, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 848, 'id_image_in_task': 692, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 849, 'id_image_in_task': 693, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 850, 'id_image_in_task': 694, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 851, 'id_image_in_task': 695, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 852, 'id_image_in_task': 696, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 853, 'id_image_in_task': 697, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 854, 'id_image_in_task': 698, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 855, 'id_image_in_task': 699, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 856, 'id_image_in_task': 700, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 857, 'id_image_in_task': 701, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 858, 'id_image_in_task': 702, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 859, 'id_image_in_task': 703, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 860, 'id_image_in_task': 704, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 861, 'id_image_in_task': 705, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 862, 'id_image_in_task': 706, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 863, 'id_image_in_task': 707, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 864, 'id_image_in_task': 708, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 865, 'id_image_in_task': 709, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 866, 'id_image_in_task': 710, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 867, 'id_image_in_task': 711, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 868, 'id_image_in_task': 712, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 869, 'id_image_in_task': 713, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 870, 'id_image_in_task': 714, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 871, 'id_image_in_task': 715, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 872, 'id_image_in_task': 716, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 873, 'id_image_in_task': 717, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 874, 'id_image_in_task': 718, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 875, 'id_image_in_task': 719, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 876, 'id_image_in_task': 720, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 877, 'id_image_in_task': 721, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 878, 'id_image_in_task': 722, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 879, 'id_image_in_task': 723, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 880, 'id_image_in_task': 724, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 881, 'id_image_in_task': 725, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 882, 'id_image_in_task': 726, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 883, 'id_image_in_task': 727, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 884, 'id_image_in_task': 728, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 885, 'id_image_in_task': 729, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 886, 'id_image_in_task': 730, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 887, 'id_image_in_task': 731, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 888, 'id_image_in_task': 732, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 889, 'id_image_in_task': 733, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 890, 'id_image_in_task': 734, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 891, 'id_image_in_task': 735, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 892, 'id_image_in_task': 736, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 893, 'id_image_in_task': 737, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 894, 'id_image_in_task': 738, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 895, 'id_image_in_task': 739, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 896, 'id_image_in_task': 740, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 897, 'id_image_in_task': 741, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 898, 'id_image_in_task': 742, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 899, 'id_image_in_task': 743, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 900, 'id_image_in_task': 744, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 901, 'id_image_in_task': 745, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 902, 'id_image_in_task': 746, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 903, 'id_image_in_task': 747, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 904, 'id_image_in_task': 748, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 905, 'id_image_in_task': 749, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 906, 'id_image_in_task': 750, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 907, 'id_image_in_task': 751, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 908, 'id_image_in_task': 752, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 909, 'id_image_in_task': 753, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 910, 'id_image_in_task': 754, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 911, 'id_image_in_task': 755, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 912, 'id_image_in_task': 756, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 913, 'id_image_in_task': 757, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 914, 'id_image_in_task': 758, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 915, 'id_image_in_task': 759, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 916, 'id_image_in_task': 760, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 917, 'id_image_in_task': 761, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 918, 'id_image_in_task': 762, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 919, 'id_image_in_task': 763, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 920, 'id_image_in_task': 764, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 921, 'id_image_in_task': 765, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 922, 'id_image_in_task': 766, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 923, 'id_image_in_task': 767, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 924, 'id_image_in_task': 768, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 925, 'id_image_in_task': 769, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 926, 'id_image_in_task': 770, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 927, 'id_image_in_task': 771, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 928, 'id_image_in_task': 772, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 929, 'id_image_in_task': 773, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 930, 'id_image_in_task': 774, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 931, 'id_image_in_task': 775, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 932, 'id_image_in_task': 776, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 933, 'id_image_in_task': 777, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 934, 'id_image_in_task': 778, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 935, 'id_image_in_task': 779, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 936, 'id_image_in_task': 780, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 937, 'id_image_in_task': 781, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 938, 'id_image_in_task': 782, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 939, 'id_image_in_task': 783, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 940, 'id_image_in_task': 784, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 941, 'id_image_in_task': 785, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 942, 'id_image_in_task': 786, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 943, 'id_image_in_task': 787, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 944, 'id_image_in_task': 788, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 945, 'id_image_in_task': 789, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 946, 'id_image_in_task': 790, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 947, 'id_image_in_task': 791, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 948, 'id_image_in_task': 792, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 949, 'id_image_in_task': 793, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 950, 'id_image_in_task': 794, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 951, 'id_image_in_task': 795, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 952, 'id_image_in_task': 796, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 953, 'id_image_in_task': 797, 'task_name': 'dermamnist', 'label': 6},\n",
       " {'id': 954, 'id_image_in_task': 798, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 955, 'id_image_in_task': 799, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 956, 'id_image_in_task': 800, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 957, 'id_image_in_task': 801, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 958, 'id_image_in_task': 802, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 959, 'id_image_in_task': 803, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 960, 'id_image_in_task': 804, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 961, 'id_image_in_task': 805, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 962, 'id_image_in_task': 806, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 963, 'id_image_in_task': 807, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 964, 'id_image_in_task': 808, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 965, 'id_image_in_task': 809, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 966, 'id_image_in_task': 810, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 967, 'id_image_in_task': 811, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 968, 'id_image_in_task': 812, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 969, 'id_image_in_task': 813, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 970, 'id_image_in_task': 814, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 971, 'id_image_in_task': 815, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 972, 'id_image_in_task': 816, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 973, 'id_image_in_task': 817, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 974, 'id_image_in_task': 818, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 975, 'id_image_in_task': 819, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 976, 'id_image_in_task': 820, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 977, 'id_image_in_task': 821, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 978, 'id_image_in_task': 822, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 979, 'id_image_in_task': 823, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 980, 'id_image_in_task': 824, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 981, 'id_image_in_task': 825, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 982, 'id_image_in_task': 826, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 983, 'id_image_in_task': 827, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 984, 'id_image_in_task': 828, 'task_name': 'dermamnist', 'label': 3},\n",
       " {'id': 985, 'id_image_in_task': 829, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 986, 'id_image_in_task': 830, 'task_name': 'dermamnist', 'label': 0},\n",
       " {'id': 987, 'id_image_in_task': 831, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 988, 'id_image_in_task': 832, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 989, 'id_image_in_task': 833, 'task_name': 'dermamnist', 'label': 1},\n",
       " {'id': 990, 'id_image_in_task': 834, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 991, 'id_image_in_task': 835, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 992, 'id_image_in_task': 836, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 993, 'id_image_in_task': 837, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 994, 'id_image_in_task': 838, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 995, 'id_image_in_task': 839, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 996, 'id_image_in_task': 840, 'task_name': 'dermamnist', 'label': 2},\n",
       " {'id': 997, 'id_image_in_task': 841, 'task_name': 'dermamnist', 'label': 5},\n",
       " {'id': 998, 'id_image_in_task': 842, 'task_name': 'dermamnist', 'label': 4},\n",
       " {'id': 999, 'id_image_in_task': 843, 'task_name': 'dermamnist', 'label': 6},\n",
       " ...]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: Finally.csv\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 7. Convert to DataFrame and save\n",
    "submission_df = pd.DataFrame(submission_entries, \n",
    "                             columns=[\"id\", \"id_image_in_task\", \"task_name\", \"label\"])\n",
    "submission_df.to_csv(\"Finally.csv\", index=False)\n",
    "print(\"Submission file created: Finally.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ---------------------------\n",
    "# Basic Residual Block\n",
    "# ---------------------------\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A simplified basic residual block with two 3x3 convolutions.\n",
    "    If the input and output dimensions differ (in channels or spatially),\n",
    "    a 1x1 convolution in the shortcut path is used.\n",
    "    \"\"\"\n",
    "    expansion = 1  # For a basic block, the number of output channels is unchanged.\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        # First convolution: may downsample if stride != 1.\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        # Second convolution: always stride 1.\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Shortcut: if the input shape differs from the output, adjust via 1x1 conv.\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
    "                          stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = torch.add(out, identity)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "# ---------------------------\n",
    "# Mini ResNet Architecture\n",
    "# ---------------------------\n",
    "class MiniResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A ResNet-inspired architecture for 3x28x28 images with fewer than 12 layers.\n",
    "    \n",
    "    Architecture summary:\n",
    "      - An initial 3x3 convolution (32 channels).\n",
    "      - Four BasicBlocks:\n",
    "          * Block 1: 32 channels, no downsampling (28x28).\n",
    "          * Block 2: 64 channels, downsampling by stride 2 (14x14).\n",
    "          * Block 3: 128 channels, downsampling by stride 2 (7x7).\n",
    "          * Block 4: 128 channels, no further downsampling (7x7).\n",
    "      - Global average pooling and a fully connected layer.\n",
    "    \n",
    "    Total convolutional layers = 1 (initial) + 4×2 (each block has 2) = 9.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MiniResNet, self).__init__()\n",
    "        # Initial convolution layer: from 3 channels to 32 channels.\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Set the current number of channels.\n",
    "        self.in_channels = 32\n",
    "        \n",
    "        # Define layers using BasicBlock:\n",
    "        self.layer1 = self._make_layer(out_channels=32, num_blocks=1, stride=1)   # 28x28\n",
    "        self.layer2 = self._make_layer(out_channels=64, num_blocks=1, stride=2)   # 14x14\n",
    "        self.layer3 = self._make_layer(out_channels=128, num_blocks=1, stride=2)  # 7x7\n",
    "        self.layer4 = self._make_layer(out_channels=128, num_blocks=1, stride=1)  # 7x7\n",
    "        \n",
    "        # Global average pooling reduces each 7x7 feature map to 1x1.\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # Final fully connected layer.\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def _make_layer(self, out_channels, num_blocks, stride):\n",
    "        \"\"\"Builds a layer (sequence of residual blocks).\"\"\"\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(BasicBlock(self.in_channels, out_channels, stride=s))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initial conv layer.\n",
    "        out = F.relu(self.bn1(self.conv1(x)))  # Output: (B, 32, 28, 28)\n",
    "        # Residual blocks.\n",
    "        out = self.layer1(out)  # Remains (B, 32, 28, 28)\n",
    "        out = self.layer2(out)  # Downsampled to (B, 64, 14, 14)\n",
    "        out = self.layer3(out)  # Downsampled to (B, 128, 7, 7)\n",
    "        out = self.layer4(out)  # Still (B, 128, 7, 7)\n",
    "        # Global average pooling.\n",
    "        out = self.avg_pool(out)  # Now (B, 128, 1, 1)\n",
    "        out = torch.flatten(out, 1)  # (B, 128)\n",
    "        out = self.fc(out)  # (B, num_classes)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "task_classes = {'breastmnist': 2,\n",
    " 'dermamnist': 7,\n",
    " 'octmnist': 4,\n",
    " 'organamnist': 11,\n",
    " 'organcmnist': 11,\n",
    " 'organsmnist': 11,\n",
    " 'pathmnist': 9,\n",
    " 'pneumoniamnist': 2,\n",
    " 'retinamnist': 5,\n",
    " 'tissuemnist': 8,\n",
    " 'bloodmnist': 8}\n",
    "\n",
    "# Set device.\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "dataset_keys = [\n",
    "    'breastmnist',\n",
    "    'dermamnist',\n",
    "    'pneumoniamnist',\n",
    "    'retinamnist',\n",
    "    #'octmnist',\n",
    "    #'organcmnist',\n",
    "    'organsmnist',\n",
    "    #'pathmnist',\n",
    "    #'tissuemnist',\n",
    "    #'bloodmnist',\n",
    "    #'organamnist'\n",
    "]\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "lr= 0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Training on dataset: breastmnist ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 -- Train Loss: 0.7135 | Train Acc: 0.6612 | Val Loss: 25.9872 | Val Acc: 0.3077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 -- Train Loss: 0.5708 | Train Acc: 0.7179 | Val Loss: 2.6785 | Val Acc: 0.3846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 -- Train Loss: 0.5495 | Train Acc: 0.7326 | Val Loss: 0.8509 | Val Acc: 0.6026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 -- Train Loss: 0.5394 | Train Acc: 0.7454 | Val Loss: 0.5227 | Val Acc: 0.7692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 -- Train Loss: 0.5181 | Train Acc: 0.7527 | Val Loss: 0.4848 | Val Acc: 0.7949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 -- Train Loss: 0.5172 | Train Acc: 0.7711 | Val Loss: 0.6352 | Val Acc: 0.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 -- Train Loss: 0.5217 | Train Acc: 0.7436 | Val Loss: 0.5132 | Val Acc: 0.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 -- Train Loss: 0.5121 | Train Acc: 0.7729 | Val Loss: 0.6107 | Val Acc: 0.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 -- Train Loss: 0.4865 | Train Acc: 0.7729 | Val Loss: 0.4744 | Val Acc: 0.7821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 -- Train Loss: 0.4884 | Train Acc: 0.7711 | Val Loss: 0.4426 | Val Acc: 0.8205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 -- Train Loss: 0.4741 | Train Acc: 0.7930 | Val Loss: 0.8459 | Val Acc: 0.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 -- Train Loss: 0.4752 | Train Acc: 0.7674 | Val Loss: 3.5240 | Val Acc: 0.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 -- Train Loss: 0.4955 | Train Acc: 0.7784 | Val Loss: 0.5776 | Val Acc: 0.7179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 -- Train Loss: 0.4920 | Train Acc: 0.7802 | Val Loss: 0.4774 | Val Acc: 0.7564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 -- Train Loss: 0.4741 | Train Acc: 0.7875 | Val Loss: 0.4777 | Val Acc: 0.7564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 -- Train Loss: 0.4995 | Train Acc: 0.7875 | Val Loss: 1.1374 | Val Acc: 0.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 -- Train Loss: 0.4746 | Train Acc: 0.7729 | Val Loss: 0.6137 | Val Acc: 0.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 -- Train Loss: 0.4549 | Train Acc: 0.7949 | Val Loss: 0.4851 | Val Acc: 0.7949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 -- Train Loss: 0.4628 | Train Acc: 0.7857 | Val Loss: 0.3845 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 -- Train Loss: 0.4704 | Train Acc: 0.7985 | Val Loss: 0.3774 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 -- Train Loss: 0.4485 | Train Acc: 0.7985 | Val Loss: 0.4667 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 -- Train Loss: 0.4380 | Train Acc: 0.8040 | Val Loss: 0.3693 | Val Acc: 0.8846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 -- Train Loss: 0.4416 | Train Acc: 0.8205 | Val Loss: 0.4771 | Val Acc: 0.7436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 -- Train Loss: 0.4531 | Train Acc: 0.7821 | Val Loss: 0.4000 | Val Acc: 0.8846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 -- Train Loss: 0.4423 | Train Acc: 0.7985 | Val Loss: 0.6280 | Val Acc: 0.7436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 -- Train Loss: 0.4433 | Train Acc: 0.7967 | Val Loss: 0.3699 | Val Acc: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 -- Train Loss: 0.4299 | Train Acc: 0.8040 | Val Loss: 0.3553 | Val Acc: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 -- Train Loss: 0.4267 | Train Acc: 0.8004 | Val Loss: 0.3996 | Val Acc: 0.7949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 -- Train Loss: 0.4424 | Train Acc: 0.8040 | Val Loss: 0.3936 | Val Acc: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 -- Train Loss: 0.4146 | Train Acc: 0.8352 | Val Loss: 0.4152 | Val Acc: 0.8205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 -- Train Loss: 0.4111 | Train Acc: 0.8205 | Val Loss: 0.3574 | Val Acc: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 -- Train Loss: 0.4062 | Train Acc: 0.8205 | Val Loss: 0.9599 | Val Acc: 0.7564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 -- Train Loss: 0.4022 | Train Acc: 0.8297 | Val Loss: 0.5123 | Val Acc: 0.7821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 -- Train Loss: 0.3866 | Train Acc: 0.8407 | Val Loss: 0.3794 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100 -- Train Loss: 0.3972 | Train Acc: 0.8132 | Val Loss: 0.4026 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 -- Train Loss: 0.4035 | Train Acc: 0.8132 | Val Loss: 0.4494 | Val Acc: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 -- Train Loss: 0.4042 | Train Acc: 0.8242 | Val Loss: 0.5929 | Val Acc: 0.7821\n",
      "Stopping early because validation loss has not improved in 10 epochs.\n",
      "Best Validation Loss: 0.3553\n",
      "Test Loss: 0.5944\n",
      "Accuracy  : 0.7500\n",
      "Precision : 0.6752\n",
      "Recall    : 0.6485\n",
      "F1 Score  : 0.6577\n",
      "-----------------------------------------------------\n",
      "\n",
      "======== Training on dataset: dermamnist ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 -- Train Loss: 0.9671 | Train Acc: 0.6602 | Val Loss: 0.8792 | Val Acc: 0.6710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 -- Train Loss: 0.8939 | Train Acc: 0.6819 | Val Loss: 0.9036 | Val Acc: 0.6780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 -- Train Loss: 0.8597 | Train Acc: 0.6886 | Val Loss: 0.8804 | Val Acc: 0.6909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 -- Train Loss: 0.8352 | Train Acc: 0.6957 | Val Loss: 0.8476 | Val Acc: 0.6879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 -- Train Loss: 0.8179 | Train Acc: 0.6996 | Val Loss: 0.7733 | Val Acc: 0.7288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 -- Train Loss: 0.8033 | Train Acc: 0.7056 | Val Loss: 0.7243 | Val Acc: 0.7258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 -- Train Loss: 0.7714 | Train Acc: 0.7143 | Val Loss: 0.7550 | Val Acc: 0.7119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 -- Train Loss: 0.7620 | Train Acc: 0.7146 | Val Loss: 0.7392 | Val Acc: 0.7328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 -- Train Loss: 0.7478 | Train Acc: 0.7243 | Val Loss: 0.7389 | Val Acc: 0.7288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 -- Train Loss: 0.7341 | Train Acc: 0.7280 | Val Loss: 0.7118 | Val Acc: 0.7498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 -- Train Loss: 0.7243 | Train Acc: 0.7317 | Val Loss: 0.7124 | Val Acc: 0.7218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 -- Train Loss: 0.7152 | Train Acc: 0.7310 | Val Loss: 0.6694 | Val Acc: 0.7567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 -- Train Loss: 0.7107 | Train Acc: 0.7351 | Val Loss: 0.6715 | Val Acc: 0.7587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 -- Train Loss: 0.6981 | Train Acc: 0.7443 | Val Loss: 0.6817 | Val Acc: 0.7547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 -- Train Loss: 0.6983 | Train Acc: 0.7375 | Val Loss: 0.6881 | Val Acc: 0.7438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 -- Train Loss: 0.6845 | Train Acc: 0.7470 | Val Loss: 0.6648 | Val Acc: 0.7587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 -- Train Loss: 0.6811 | Train Acc: 0.7420 | Val Loss: 0.6803 | Val Acc: 0.7507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 -- Train Loss: 0.6786 | Train Acc: 0.7485 | Val Loss: 0.6562 | Val Acc: 0.7617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 -- Train Loss: 0.6768 | Train Acc: 0.7458 | Val Loss: 0.6417 | Val Acc: 0.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 -- Train Loss: 0.6681 | Train Acc: 0.7488 | Val Loss: 0.6746 | Val Acc: 0.7557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 -- Train Loss: 0.6690 | Train Acc: 0.7544 | Val Loss: 0.6472 | Val Acc: 0.7727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 -- Train Loss: 0.6570 | Train Acc: 0.7458 | Val Loss: 0.6370 | Val Acc: 0.7657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 -- Train Loss: 0.6541 | Train Acc: 0.7555 | Val Loss: 0.6575 | Val Acc: 0.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 -- Train Loss: 0.6474 | Train Acc: 0.7562 | Val Loss: 0.6152 | Val Acc: 0.7737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 -- Train Loss: 0.6465 | Train Acc: 0.7574 | Val Loss: 0.6678 | Val Acc: 0.7478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 -- Train Loss: 0.6473 | Train Acc: 0.7590 | Val Loss: 0.6599 | Val Acc: 0.7577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 -- Train Loss: 0.6336 | Train Acc: 0.7608 | Val Loss: 0.6725 | Val Acc: 0.7368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 -- Train Loss: 0.6317 | Train Acc: 0.7640 | Val Loss: 0.6257 | Val Acc: 0.7767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 -- Train Loss: 0.6204 | Train Acc: 0.7667 | Val Loss: 0.6491 | Val Acc: 0.7647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 -- Train Loss: 0.6228 | Train Acc: 0.7611 | Val Loss: 0.6585 | Val Acc: 0.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 -- Train Loss: 0.6241 | Train Acc: 0.7702 | Val Loss: 0.6511 | Val Acc: 0.7617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 -- Train Loss: 0.6116 | Train Acc: 0.7681 | Val Loss: 0.6294 | Val Acc: 0.7667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 -- Train Loss: 0.6093 | Train Acc: 0.7617 | Val Loss: 0.6268 | Val Acc: 0.7697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 -- Train Loss: 0.6024 | Train Acc: 0.7729 | Val Loss: 0.6442 | Val Acc: 0.7647\n",
      "Stopping early because validation loss has not improved in 10 epochs.\n",
      "Best Validation Loss: 0.6152\n",
      "Test Loss: 0.6425\n",
      "Accuracy  : 0.7486\n",
      "Precision : 0.6086\n",
      "Recall    : 0.4834\n",
      "F1 Score  : 0.5131\n",
      "-----------------------------------------------------\n",
      "\n",
      "======== Training on dataset: pneumoniamnist ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 -- Train Loss: 0.3047 | Train Acc: 0.8702 | Val Loss: 0.4171 | Val Acc: 0.8416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 -- Train Loss: 0.2034 | Train Acc: 0.9186 | Val Loss: 0.2739 | Val Acc: 0.9160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 -- Train Loss: 0.1791 | Train Acc: 0.9295 | Val Loss: 0.2263 | Val Acc: 0.9294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 -- Train Loss: 0.1744 | Train Acc: 0.9322 | Val Loss: 0.3684 | Val Acc: 0.8378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 -- Train Loss: 0.1655 | Train Acc: 0.9397 | Val Loss: 0.1582 | Val Acc: 0.9447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 -- Train Loss: 0.1626 | Train Acc: 0.9335 | Val Loss: 0.3250 | Val Acc: 0.8779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 -- Train Loss: 0.1539 | Train Acc: 0.9422 | Val Loss: 0.4283 | Val Acc: 0.8168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 -- Train Loss: 0.1434 | Train Acc: 0.9424 | Val Loss: 0.1192 | Val Acc: 0.9447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 -- Train Loss: 0.1409 | Train Acc: 0.9439 | Val Loss: 0.1424 | Val Acc: 0.9466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 -- Train Loss: 0.1264 | Train Acc: 0.9492 | Val Loss: 0.1006 | Val Acc: 0.9676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 -- Train Loss: 0.1215 | Train Acc: 0.9526 | Val Loss: 0.1811 | Val Acc: 0.9332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 -- Train Loss: 0.1273 | Train Acc: 0.9497 | Val Loss: 0.1159 | Val Acc: 0.9504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 -- Train Loss: 0.1142 | Train Acc: 0.9541 | Val Loss: 0.1581 | Val Acc: 0.9332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 -- Train Loss: 0.1243 | Train Acc: 0.9518 | Val Loss: 0.1570 | Val Acc: 0.9332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 -- Train Loss: 0.1208 | Train Acc: 0.9539 | Val Loss: 0.1033 | Val Acc: 0.9561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 -- Train Loss: 0.1045 | Train Acc: 0.9588 | Val Loss: 0.1298 | Val Acc: 0.9523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 -- Train Loss: 0.1128 | Train Acc: 0.9552 | Val Loss: 0.1256 | Val Acc: 0.9447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 -- Train Loss: 0.1015 | Train Acc: 0.9588 | Val Loss: 0.1278 | Val Acc: 0.9599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 -- Train Loss: 0.1078 | Train Acc: 0.9605 | Val Loss: 0.0856 | Val Acc: 0.9695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 -- Train Loss: 0.0984 | Train Acc: 0.9641 | Val Loss: 0.0882 | Val Acc: 0.9733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[166], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Train the model, monitoring validation loss\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m model \u001b[38;5;241m=\u001b[39m train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Once training is complete, evaluate on the test set\u001b[39;00m\n\u001b[1;32m     35\u001b[0m evaluate_model(model, test_loader, criterion, device)\n",
      "Cell \u001b[0;32mIn[161], line 25\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, patience)\u001b[0m\n\u001b[1;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels\u001b[38;5;241m.\u001b[39mlong())\n\u001b[1;32m     24\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     27\u001b[0m running_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Calculate batch accuracy\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/pytorch-test/env/lib/python3.11/site-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/pytorch-test/env/lib/python3.11/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Documents/pytorch-test/env/lib/python3.11/site-packages/torch/optim/adam.py:244\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    232\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    234\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    235\u001b[0m         group,\n\u001b[1;32m    236\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m         state_steps,\n\u001b[1;32m    242\u001b[0m     )\n\u001b[0;32m--> 244\u001b[0m     adam(\n\u001b[1;32m    245\u001b[0m         params_with_grad,\n\u001b[1;32m    246\u001b[0m         grads,\n\u001b[1;32m    247\u001b[0m         exp_avgs,\n\u001b[1;32m    248\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    249\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    250\u001b[0m         state_steps,\n\u001b[1;32m    251\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    252\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    253\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    254\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    255\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    256\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    257\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    258\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    259\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    260\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    261\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    262\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    263\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    264\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    265\u001b[0m     )\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Documents/pytorch-test/env/lib/python3.11/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/pytorch-test/env/lib/python3.11/site-packages/torch/optim/adam.py:876\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    874\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 876\u001b[0m func(\n\u001b[1;32m    877\u001b[0m     params,\n\u001b[1;32m    878\u001b[0m     grads,\n\u001b[1;32m    879\u001b[0m     exp_avgs,\n\u001b[1;32m    880\u001b[0m     exp_avg_sqs,\n\u001b[1;32m    881\u001b[0m     max_exp_avg_sqs,\n\u001b[1;32m    882\u001b[0m     state_steps,\n\u001b[1;32m    883\u001b[0m     amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m    884\u001b[0m     has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    885\u001b[0m     beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    886\u001b[0m     beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    887\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m    888\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[1;32m    889\u001b[0m     eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    890\u001b[0m     maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[1;32m    891\u001b[0m     capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m    892\u001b[0m     differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[1;32m    893\u001b[0m     grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[1;32m    894\u001b[0m     found_inf\u001b[38;5;241m=\u001b[39mfound_inf,\n\u001b[1;32m    895\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/pytorch-test/env/lib/python3.11/site-packages/torch/optim/adam.py:476\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    474\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 476\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    478\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "for key in dataset_keys:\n",
    "    print(f\"======== Training on dataset: {key} ========\")\n",
    "    npz_path = f\"./data/{key}.npz\"\n",
    "    info = INFO[key]\n",
    "    n_channels = info.get('n_channels', 1)\n",
    "    # Get transforms. For this example, we assume images are single-channel.\n",
    "    train_transform, val_transform, test_transform = get_transforms(n_channels)\n",
    "    \n",
    "    # Create dataset splits\n",
    "    train_dataset = MyMedNISTDataset(npz_path=npz_path, split='train', transform=train_transform)\n",
    "    val_dataset   = MyMedNISTDataset(npz_path=npz_path, split='val', transform=val_transform)\n",
    "    test_dataset  = MyMedNISTDataset(npz_path=npz_path, split='test', transform=test_transform)\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Create a new instance of your model\n",
    "    # (Assuming the number of classes is task_classes[key])\n",
    "    model = MiniResNet(num_classes=task_classes[key])\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Train the model, monitoring validation loss\n",
    "    model = train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=num_epochs, patience=10)\n",
    "    \n",
    "    # Once training is complete, evaluate on the test set\n",
    "    evaluate_model(model, test_loader, criterion, device)\n",
    "    \n",
    "    # Free up memory for the next dataset\n",
    "    del model, train_dataset, val_dataset, test_dataset, train_loader, val_loader, test_loader\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"-----------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MyCNN, self).__init__()\n",
    "        # conv2d --> (None, 28, 28, 32)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, \n",
    "                               out_channels=32, \n",
    "                               kernel_size=3, \n",
    "                               padding=1)  # 'same' padding\n",
    "        # max_pooling2d --> (None, 28, 28, 32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=1, stride=1)\n",
    "        \n",
    "        # conv2d_1 --> (None, 28, 28, 32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, \n",
    "                               out_channels=32, \n",
    "                               kernel_size=3, \n",
    "                               padding=1)\n",
    "        # conv2d_2 --> (None, 28, 28, 64)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, \n",
    "                               out_channels=64, \n",
    "                               kernel_size=3, \n",
    "                               padding=1)\n",
    "        # conv2d_3 --> (None, 28, 28, 128)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, \n",
    "                               out_channels=128, \n",
    "                               kernel_size=3, \n",
    "                               padding=1)\n",
    "        # max_pooling2d_1 --> (None, 28, 28, 128)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=1, stride=1)\n",
    "        \n",
    "        # flatten --> (None, 100352)\n",
    "        self.fc1 = nn.Linear(in_features=28*28*128, \n",
    "                             out_features=128)\n",
    "        \n",
    "        # dense --> (None, 128)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        # dense_1 --> (None, 1)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)  # or torch.flatten(x, 1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "\n",
    "def train_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    device, \n",
    "    num_epochs=20,\n",
    "    patience=10  # Number of epochs with no improvement to allow\n",
    "):\n",
    "    \"\"\"\n",
    "    Example cyclical LR parameters (uncomment & adjust if you want to use them):\n",
    "      scheduler = CyclicLR(\n",
    "          optimizer,\n",
    "          base_lr=1e-4,\n",
    "          max_lr=1e-3,\n",
    "          step_size_up=50,\n",
    "          step_size_down=50,\n",
    "          mode='triangular',\n",
    "          cycle_momentum=False\n",
    "      )\n",
    "    \"\"\"\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    best_val_loss_epoch = 0  # Tracks the epoch index of the best val loss\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # --------------------\n",
    "        # Training Phase\n",
    "        # --------------------\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\", leave=False)\n",
    "        for batch_idx, (images, labels) in enumerate(train_pbar):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # If using CyclicLR, uncomment below:\n",
    "            # scheduler.step()\n",
    "\n",
    "            running_train_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # Calculate batch accuracy\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            train_correct += (preds == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "            train_pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        train_loss = running_train_loss / len(train_loader.dataset)\n",
    "        train_acc = train_correct / train_total\n",
    "\n",
    "        # --------------------\n",
    "        # Validation Phase\n",
    "        # --------------------\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_pbar:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "                running_val_loss += loss.item() * images.size(0)\n",
    "                \n",
    "                # Calculate batch accuracy\n",
    "                _, preds = torch.max(outputs, dim=1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "                \n",
    "                val_pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        # Print metrics for this epoch\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} -- \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        # --------------------\n",
    "        # Check for best model & early stopping\n",
    "        # --------------------\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            best_val_loss_epoch = epoch  # reset patience counter\n",
    "        else:\n",
    "            # If we haven't improved for 'patience' epochs, stop\n",
    "            if (epoch - best_val_loss_epoch) >= patience:\n",
    "                print(f\"No improvement for {patience} epochs. Stopping early.\")\n",
    "                break\n",
    "\n",
    "        # (Optional) If you want to monitor current LR, uncomment:\n",
    "        # for param_group in optimizer.param_groups:\n",
    "        #     print(f\"Current LR: {param_group['lr']}\")\n",
    "\n",
    "    print(f\"Best Validation Loss: {best_val_loss:.4f}\")\n",
    "    # Restore the best model weights\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "task_classes = {'breastmnist': 2,\n",
    " 'dermamnist': 7,\n",
    " 'octmnist': 4,\n",
    " 'organamnist': 11,\n",
    " 'organcmnist': 11,\n",
    " 'organsmnist': 11,\n",
    " 'pathmnist': 9,\n",
    " 'pneumoniamnist': 2,\n",
    " 'retinamnist': 5,\n",
    " 'tissuemnist': 8,\n",
    " 'bloodmnist': 8}\n",
    "\n",
    "# Set device.\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "dataset_keys = [\n",
    "    'breastmnist',\n",
    "    'dermamnist',\n",
    "    'pneumoniamnist',\n",
    "    'retinamnist',\n",
    "    #'octmnist',\n",
    "    'organcmnist',\n",
    "    'organsmnist',\n",
    "    #'pathmnist',\n",
    "    #'tissuemnist',\n",
    "    #'bloodmnist',\n",
    "    'organamnist'\n",
    "]\n",
    "\n",
    "num_epochs = 150\n",
    "batch_size = 64\n",
    "lr= 0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Training on dataset: breastmnist ========\n",
      "Computed class weights for breastmnist: [1.46153846 0.53846154]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 -- Train Loss: 0.7153 | Train Acc: 0.6813 | Val Loss: 0.5892 | Val Acc: 0.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 -- Train Loss: 0.5780 | Train Acc: 0.7308 | Val Loss: 0.5677 | Val Acc: 0.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150 -- Train Loss: 0.5739 | Train Acc: 0.7308 | Val Loss: 0.5600 | Val Acc: 0.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 -- Train Loss: 0.5461 | Train Acc: 0.7308 | Val Loss: 0.5297 | Val Acc: 0.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 -- Train Loss: 0.5449 | Train Acc: 0.7344 | Val Loss: 0.5066 | Val Acc: 0.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/150 -- Train Loss: 0.5402 | Train Acc: 0.7418 | Val Loss: 0.5182 | Val Acc: 0.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/150 -- Train Loss: 0.5352 | Train Acc: 0.7326 | Val Loss: 0.4695 | Val Acc: 0.7949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/150 -- Train Loss: 0.5245 | Train Acc: 0.7509 | Val Loss: 0.4872 | Val Acc: 0.8077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/150 -- Train Loss: 0.5208 | Train Acc: 0.7692 | Val Loss: 0.4895 | Val Acc: 0.8077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/150 -- Train Loss: 0.5161 | Train Acc: 0.7674 | Val Loss: 0.5104 | Val Acc: 0.7692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/150 -- Train Loss: 0.5276 | Train Acc: 0.7491 | Val Loss: 0.4893 | Val Acc: 0.7949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/150 -- Train Loss: 0.4951 | Train Acc: 0.7619 | Val Loss: 0.4719 | Val Acc: 0.8077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/150 -- Train Loss: 0.4685 | Train Acc: 0.7857 | Val Loss: 0.4532 | Val Acc: 0.8077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/150 -- Train Loss: 0.5077 | Train Acc: 0.7656 | Val Loss: 0.4785 | Val Acc: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/150 -- Train Loss: 0.5089 | Train Acc: 0.7546 | Val Loss: 0.4708 | Val Acc: 0.8205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/150 -- Train Loss: 0.4771 | Train Acc: 0.7784 | Val Loss: 0.4538 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/150 -- Train Loss: 0.4873 | Train Acc: 0.7766 | Val Loss: 0.4453 | Val Acc: 0.8077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/150 -- Train Loss: 0.4908 | Train Acc: 0.7564 | Val Loss: 0.4547 | Val Acc: 0.8205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/150 -- Train Loss: 0.4711 | Train Acc: 0.7857 | Val Loss: 0.4329 | Val Acc: 0.8590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/150 -- Train Loss: 0.4541 | Train Acc: 0.7711 | Val Loss: 0.4444 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/150 -- Train Loss: 0.4631 | Train Acc: 0.8004 | Val Loss: 0.4243 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/150 -- Train Loss: 0.4776 | Train Acc: 0.7821 | Val Loss: 0.4890 | Val Acc: 0.7564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/150 -- Train Loss: 0.5002 | Train Acc: 0.7619 | Val Loss: 0.4719 | Val Acc: 0.7949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/150 -- Train Loss: 0.4884 | Train Acc: 0.7875 | Val Loss: 0.4669 | Val Acc: 0.7949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/150 -- Train Loss: 0.4914 | Train Acc: 0.7857 | Val Loss: 0.4489 | Val Acc: 0.8205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/150 -- Train Loss: 0.4699 | Train Acc: 0.7839 | Val Loss: 0.4418 | Val Acc: 0.8590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150 -- Train Loss: 0.4582 | Train Acc: 0.7875 | Val Loss: 0.4300 | Val Acc: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/150 -- Train Loss: 0.4354 | Train Acc: 0.8040 | Val Loss: 0.4060 | Val Acc: 0.8590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/150 -- Train Loss: 0.4726 | Train Acc: 0.8022 | Val Loss: 0.3878 | Val Acc: 0.8590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/150 -- Train Loss: 0.4493 | Train Acc: 0.8168 | Val Loss: 0.3934 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/150 -- Train Loss: 0.4299 | Train Acc: 0.8223 | Val Loss: 0.4168 | Val Acc: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/150 -- Train Loss: 0.4377 | Train Acc: 0.8077 | Val Loss: 0.4302 | Val Acc: 0.8205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/150 -- Train Loss: 0.4403 | Train Acc: 0.8059 | Val Loss: 0.3826 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/150 -- Train Loss: 0.4265 | Train Acc: 0.8095 | Val Loss: 0.3932 | Val Acc: 0.8590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/150 -- Train Loss: 0.3984 | Train Acc: 0.8150 | Val Loss: 0.4378 | Val Acc: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/150 -- Train Loss: 0.4119 | Train Acc: 0.8187 | Val Loss: 0.3603 | Val Acc: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/150 -- Train Loss: 0.4173 | Train Acc: 0.8095 | Val Loss: 0.3758 | Val Acc: 0.8590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/150 -- Train Loss: 0.3835 | Train Acc: 0.8260 | Val Loss: 0.3731 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/150 -- Train Loss: 0.4068 | Train Acc: 0.8132 | Val Loss: 0.3262 | Val Acc: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/150 -- Train Loss: 0.3936 | Train Acc: 0.8132 | Val Loss: 0.3439 | Val Acc: 0.8974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/150 -- Train Loss: 0.4008 | Train Acc: 0.8260 | Val Loss: 0.3519 | Val Acc: 0.8846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/150 -- Train Loss: 0.3958 | Train Acc: 0.8077 | Val Loss: 0.4033 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/150 -- Train Loss: 0.3931 | Train Acc: 0.8168 | Val Loss: 0.3669 | Val Acc: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/150 -- Train Loss: 0.3829 | Train Acc: 0.8278 | Val Loss: 0.3434 | Val Acc: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/150 -- Train Loss: 0.3896 | Train Acc: 0.8278 | Val Loss: 0.3335 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/150 -- Train Loss: 0.3533 | Train Acc: 0.8352 | Val Loss: 0.3124 | Val Acc: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/150 -- Train Loss: 0.3735 | Train Acc: 0.8480 | Val Loss: 0.3107 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/150 -- Train Loss: 0.3550 | Train Acc: 0.8462 | Val Loss: 0.3173 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/150 -- Train Loss: 0.3391 | Train Acc: 0.8425 | Val Loss: 0.3481 | Val Acc: 0.8846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/150 -- Train Loss: 0.3462 | Train Acc: 0.8333 | Val Loss: 0.3465 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/150 -- Train Loss: 0.3468 | Train Acc: 0.8553 | Val Loss: 0.2971 | Val Acc: 0.9103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/150 -- Train Loss: 0.3354 | Train Acc: 0.8425 | Val Loss: 0.3346 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/150 -- Train Loss: 0.3016 | Train Acc: 0.8681 | Val Loss: 0.2896 | Val Acc: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/150 -- Train Loss: 0.3155 | Train Acc: 0.8681 | Val Loss: 0.3367 | Val Acc: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/150 -- Train Loss: 0.3783 | Train Acc: 0.8516 | Val Loss: 0.3045 | Val Acc: 0.8974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/150 -- Train Loss: 0.3198 | Train Acc: 0.8645 | Val Loss: 0.3549 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150 -- Train Loss: 0.2942 | Train Acc: 0.8810 | Val Loss: 0.3005 | Val Acc: 0.8846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/150 -- Train Loss: 0.2996 | Train Acc: 0.8736 | Val Loss: 0.3161 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150 -- Train Loss: 0.3062 | Train Acc: 0.8700 | Val Loss: 0.3445 | Val Acc: 0.8590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/150 -- Train Loss: 0.2869 | Train Acc: 0.8645 | Val Loss: 0.3134 | Val Acc: 0.8846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150 -- Train Loss: 0.2623 | Train Acc: 0.8864 | Val Loss: 0.3114 | Val Acc: 0.8590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/150 -- Train Loss: 0.2906 | Train Acc: 0.8663 | Val Loss: 0.3603 | Val Acc: 0.8590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/150 -- Train Loss: 0.2969 | Train Acc: 0.8700 | Val Loss: 0.2856 | Val Acc: 0.8590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/150 -- Train Loss: 0.2599 | Train Acc: 0.8919 | Val Loss: 0.3230 | Val Acc: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/150 -- Train Loss: 0.2641 | Train Acc: 0.8828 | Val Loss: 0.3634 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/150 -- Train Loss: 0.2805 | Train Acc: 0.8846 | Val Loss: 0.3033 | Val Acc: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/150 -- Train Loss: 0.2875 | Train Acc: 0.8736 | Val Loss: 0.2758 | Val Acc: 0.8846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/150 -- Train Loss: 0.2803 | Train Acc: 0.8663 | Val Loss: 0.2985 | Val Acc: 0.9103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/150 -- Train Loss: 0.2478 | Train Acc: 0.8828 | Val Loss: 0.2572 | Val Acc: 0.9103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/150 -- Train Loss: 0.2474 | Train Acc: 0.8791 | Val Loss: 0.2594 | Val Acc: 0.8846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/150 -- Train Loss: 0.2418 | Train Acc: 0.9011 | Val Loss: 0.2971 | Val Acc: 0.8590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/150 -- Train Loss: 0.2582 | Train Acc: 0.8791 | Val Loss: 0.3038 | Val Acc: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/150 -- Train Loss: 0.2073 | Train Acc: 0.9194 | Val Loss: 0.2974 | Val Acc: 0.8974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/150 -- Train Loss: 0.2257 | Train Acc: 0.9121 | Val Loss: 0.3292 | Val Acc: 0.8846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/150 -- Train Loss: 0.2536 | Train Acc: 0.8956 | Val Loss: 0.3684 | Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/150 -- Train Loss: 0.2504 | Train Acc: 0.8864 | Val Loss: 0.3167 | Val Acc: 0.8590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/150 -- Train Loss: 0.2401 | Train Acc: 0.8938 | Val Loss: 0.2962 | Val Acc: 0.8590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/150 -- Train Loss: 0.2100 | Train Acc: 0.9158 | Val Loss: 0.2943 | Val Acc: 0.9103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/150 -- Train Loss: 0.2395 | Train Acc: 0.8956 | Val Loss: 0.2736 | Val Acc: 0.8718\n",
      "No improvement for 10 epochs. Stopping early.\n",
      "Best Validation Loss: 0.2572\n",
      "Test Loss: 0.4715\n",
      "Accuracy  : 0.8141\n",
      "Precision : 0.7636\n",
      "Recall    : 0.7675\n",
      "F1 Score  : 0.7655\n",
      "-----------------------------------------------------\n",
      "\n",
      "======== Training on dataset: dermamnist ========\n",
      "Computed class weights for dermamnist: [0.94264888 0.59867394 0.27948497 2.68654932 0.27589723 0.04579671\n",
      " 2.17094894]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 -- Train Loss: 1.0394 | Train Acc: 0.6581 | Val Loss: 0.9302 | Val Acc: 0.6770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 -- Train Loss: 0.9353 | Train Acc: 0.6785 | Val Loss: 0.8321 | Val Acc: 0.6700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150 -- Train Loss: 0.8975 | Train Acc: 0.6796 | Val Loss: 0.8119 | Val Acc: 0.6859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 -- Train Loss: 0.8734 | Train Acc: 0.6875 | Val Loss: 0.7888 | Val Acc: 0.7009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 -- Train Loss: 0.8510 | Train Acc: 0.6929 | Val Loss: 0.7812 | Val Acc: 0.7009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/150 -- Train Loss: 0.8490 | Train Acc: 0.6942 | Val Loss: 0.8068 | Val Acc: 0.7109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/150 -- Train Loss: 0.8344 | Train Acc: 0.6956 | Val Loss: 0.7522 | Val Acc: 0.7218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/150 -- Train Loss: 0.8149 | Train Acc: 0.7006 | Val Loss: 0.7413 | Val Acc: 0.7258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/150 -- Train Loss: 0.8098 | Train Acc: 0.7059 | Val Loss: 0.7535 | Val Acc: 0.7228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/150 -- Train Loss: 0.8105 | Train Acc: 0.7057 | Val Loss: 0.7366 | Val Acc: 0.7208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/150 -- Train Loss: 0.7851 | Train Acc: 0.7090 | Val Loss: 0.7292 | Val Acc: 0.7298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/150 -- Train Loss: 0.7893 | Train Acc: 0.7091 | Val Loss: 0.7553 | Val Acc: 0.7188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/150 -- Train Loss: 0.7760 | Train Acc: 0.7141 | Val Loss: 0.7233 | Val Acc: 0.7328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/150 -- Train Loss: 0.7695 | Train Acc: 0.7177 | Val Loss: 0.7109 | Val Acc: 0.7328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/150 -- Train Loss: 0.7697 | Train Acc: 0.7147 | Val Loss: 0.7096 | Val Acc: 0.7408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/150 -- Train Loss: 0.7678 | Train Acc: 0.7179 | Val Loss: 0.7276 | Val Acc: 0.7388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/150 -- Train Loss: 0.7702 | Train Acc: 0.7183 | Val Loss: 0.7440 | Val Acc: 0.7378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/150 -- Train Loss: 0.7478 | Train Acc: 0.7253 | Val Loss: 0.6992 | Val Acc: 0.7478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/150 -- Train Loss: 0.7544 | Train Acc: 0.7230 | Val Loss: 0.7076 | Val Acc: 0.7408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/150 -- Train Loss: 0.7253 | Train Acc: 0.7354 | Val Loss: 0.6768 | Val Acc: 0.7498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/150 -- Train Loss: 0.7309 | Train Acc: 0.7297 | Val Loss: 0.7131 | Val Acc: 0.7438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/150 -- Train Loss: 0.7169 | Train Acc: 0.7344 | Val Loss: 0.6974 | Val Acc: 0.7577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/150 -- Train Loss: 0.7229 | Train Acc: 0.7284 | Val Loss: 0.6836 | Val Acc: 0.7428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/150 -- Train Loss: 0.7082 | Train Acc: 0.7374 | Val Loss: 0.6795 | Val Acc: 0.7458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/150 -- Train Loss: 0.7006 | Train Acc: 0.7330 | Val Loss: 0.6704 | Val Acc: 0.7488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/150 -- Train Loss: 0.6914 | Train Acc: 0.7374 | Val Loss: 0.6718 | Val Acc: 0.7697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150 -- Train Loss: 0.6801 | Train Acc: 0.7458 | Val Loss: 0.6691 | Val Acc: 0.7567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/150 -- Train Loss: 0.6794 | Train Acc: 0.7440 | Val Loss: 0.6813 | Val Acc: 0.7687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/150 -- Train Loss: 0.6949 | Train Acc: 0.7395 | Val Loss: 0.6708 | Val Acc: 0.7717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/150 -- Train Loss: 0.6837 | Train Acc: 0.7474 | Val Loss: 0.6789 | Val Acc: 0.7647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/150 -- Train Loss: 0.6866 | Train Acc: 0.7455 | Val Loss: 0.6820 | Val Acc: 0.7378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/150 -- Train Loss: 0.6606 | Train Acc: 0.7504 | Val Loss: 0.6626 | Val Acc: 0.7667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/150 -- Train Loss: 0.6620 | Train Acc: 0.7501 | Val Loss: 0.6772 | Val Acc: 0.7498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/150 -- Train Loss: 0.6670 | Train Acc: 0.7484 | Val Loss: 0.6737 | Val Acc: 0.7687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/150 -- Train Loss: 0.6576 | Train Acc: 0.7502 | Val Loss: 0.6809 | Val Acc: 0.7687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/150 -- Train Loss: 0.6463 | Train Acc: 0.7511 | Val Loss: 0.6643 | Val Acc: 0.7647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/150 -- Train Loss: 0.6413 | Train Acc: 0.7577 | Val Loss: 0.6709 | Val Acc: 0.7597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/150 -- Train Loss: 0.6399 | Train Acc: 0.7565 | Val Loss: 0.6852 | Val Acc: 0.7577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/150 -- Train Loss: 0.6430 | Train Acc: 0.7578 | Val Loss: 0.6611 | Val Acc: 0.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/150 -- Train Loss: 0.6324 | Train Acc: 0.7647 | Val Loss: 0.6719 | Val Acc: 0.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/150 -- Train Loss: 0.6267 | Train Acc: 0.7595 | Val Loss: 0.6749 | Val Acc: 0.7647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/150 -- Train Loss: 0.6283 | Train Acc: 0.7580 | Val Loss: 0.6779 | Val Acc: 0.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/150 -- Train Loss: 0.6171 | Train Acc: 0.7664 | Val Loss: 0.6865 | Val Acc: 0.7687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/150 -- Train Loss: 0.6178 | Train Acc: 0.7640 | Val Loss: 0.6799 | Val Acc: 0.7727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/150 -- Train Loss: 0.6151 | Train Acc: 0.7685 | Val Loss: 0.6656 | Val Acc: 0.7767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/150 -- Train Loss: 0.6087 | Train Acc: 0.7681 | Val Loss: 0.6761 | Val Acc: 0.7737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/150 -- Train Loss: 0.5911 | Train Acc: 0.7719 | Val Loss: 0.6785 | Val Acc: 0.7757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/150 -- Train Loss: 0.6005 | Train Acc: 0.7694 | Val Loss: 0.6864 | Val Acc: 0.7617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/150 -- Train Loss: 0.5767 | Train Acc: 0.7816 | Val Loss: 0.6805 | Val Acc: 0.7797\n",
      "No improvement for 10 epochs. Stopping early.\n",
      "Best Validation Loss: 0.6611\n",
      "Test Loss: 0.6589\n",
      "Accuracy  : 0.7576\n",
      "Precision : 0.6626\n",
      "Recall    : 0.4566\n",
      "F1 Score  : 0.4885\n",
      "-----------------------------------------------------\n",
      "\n",
      "======== Training on dataset: pneumoniamnist ========\n",
      "Computed class weights for pneumoniamnist: [1.48428207 0.51571793]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 -- Train Loss: 0.3539 | Train Acc: 0.8407 | Val Loss: 0.2052 | Val Acc: 0.9313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 -- Train Loss: 0.2033 | Train Acc: 0.9189 | Val Loss: 0.1675 | Val Acc: 0.9389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150 -- Train Loss: 0.1803 | Train Acc: 0.9288 | Val Loss: 0.1358 | Val Acc: 0.9542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 -- Train Loss: 0.1608 | Train Acc: 0.9403 | Val Loss: 0.1471 | Val Acc: 0.9485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 -- Train Loss: 0.1556 | Train Acc: 0.9441 | Val Loss: 0.1093 | Val Acc: 0.9695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/150 -- Train Loss: 0.1383 | Train Acc: 0.9469 | Val Loss: 0.1087 | Val Acc: 0.9485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/150 -- Train Loss: 0.1345 | Train Acc: 0.9520 | Val Loss: 0.1139 | Val Acc: 0.9618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/150 -- Train Loss: 0.1407 | Train Acc: 0.9492 | Val Loss: 0.0952 | Val Acc: 0.9656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/150 -- Train Loss: 0.1298 | Train Acc: 0.9535 | Val Loss: 0.1065 | Val Acc: 0.9695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/150 -- Train Loss: 0.1198 | Train Acc: 0.9582 | Val Loss: 0.0936 | Val Acc: 0.9695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/150 -- Train Loss: 0.1227 | Train Acc: 0.9556 | Val Loss: 0.1075 | Val Acc: 0.9618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/150 -- Train Loss: 0.1185 | Train Acc: 0.9548 | Val Loss: 0.0971 | Val Acc: 0.9695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/150 -- Train Loss: 0.1144 | Train Acc: 0.9577 | Val Loss: 0.0817 | Val Acc: 0.9733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/150 -- Train Loss: 0.1041 | Train Acc: 0.9605 | Val Loss: 0.1141 | Val Acc: 0.9580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/150 -- Train Loss: 0.1175 | Train Acc: 0.9543 | Val Loss: 0.1142 | Val Acc: 0.9599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/150 -- Train Loss: 0.1032 | Train Acc: 0.9618 | Val Loss: 0.0884 | Val Acc: 0.9599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/150 -- Train Loss: 0.1075 | Train Acc: 0.9592 | Val Loss: 0.0779 | Val Acc: 0.9695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/150 -- Train Loss: 0.1130 | Train Acc: 0.9620 | Val Loss: 0.0814 | Val Acc: 0.9695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/150 -- Train Loss: 0.1036 | Train Acc: 0.9599 | Val Loss: 0.0907 | Val Acc: 0.9656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/150 -- Train Loss: 0.0992 | Train Acc: 0.9630 | Val Loss: 0.0838 | Val Acc: 0.9676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/150 -- Train Loss: 0.1035 | Train Acc: 0.9633 | Val Loss: 0.0902 | Val Acc: 0.9676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/150 -- Train Loss: 0.0891 | Train Acc: 0.9688 | Val Loss: 0.0788 | Val Acc: 0.9676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/150 -- Train Loss: 0.0998 | Train Acc: 0.9622 | Val Loss: 0.0980 | Val Acc: 0.9618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/150 -- Train Loss: 0.0945 | Train Acc: 0.9660 | Val Loss: 0.0880 | Val Acc: 0.9695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/150 -- Train Loss: 0.0908 | Train Acc: 0.9684 | Val Loss: 0.1073 | Val Acc: 0.9504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/150 -- Train Loss: 0.0980 | Train Acc: 0.9654 | Val Loss: 0.1010 | Val Acc: 0.9561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150 -- Train Loss: 0.0931 | Train Acc: 0.9688 | Val Loss: 0.0948 | Val Acc: 0.9599\n",
      "No improvement for 10 epochs. Stopping early.\n",
      "Best Validation Loss: 0.0779\n",
      "Test Loss: 0.5760\n",
      "Accuracy  : 0.8766\n",
      "Precision : 0.9084\n",
      "Recall    : 0.8389\n",
      "F1 Score  : 0.8582\n",
      "-----------------------------------------------------\n",
      "\n",
      "======== Training on dataset: retinamnist ========\n",
      "Computed class weights for retinamnist: [0.29368767 1.11509536 0.69287478 0.73573302 2.16260918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 -- Train Loss: 1.4821 | Train Acc: 0.4102 | Val Loss: 1.2694 | Val Acc: 0.4667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 -- Train Loss: 1.2994 | Train Acc: 0.4630 | Val Loss: 1.1273 | Val Acc: 0.4667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150 -- Train Loss: 1.2532 | Train Acc: 0.4704 | Val Loss: 1.2145 | Val Acc: 0.4250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 -- Train Loss: 1.2207 | Train Acc: 0.4907 | Val Loss: 1.1254 | Val Acc: 0.4833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 -- Train Loss: 1.2053 | Train Acc: 0.5009 | Val Loss: 1.1357 | Val Acc: 0.5167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/150 -- Train Loss: 1.1907 | Train Acc: 0.5000 | Val Loss: 1.1061 | Val Acc: 0.4667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/150 -- Train Loss: 1.2115 | Train Acc: 0.4954 | Val Loss: 1.1100 | Val Acc: 0.4833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/150 -- Train Loss: 1.1838 | Train Acc: 0.5046 | Val Loss: 1.0837 | Val Acc: 0.5583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/150 -- Train Loss: 1.1865 | Train Acc: 0.5028 | Val Loss: 1.0755 | Val Acc: 0.4833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/150 -- Train Loss: 1.1998 | Train Acc: 0.4917 | Val Loss: 1.1191 | Val Acc: 0.5333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/150 -- Train Loss: 1.1895 | Train Acc: 0.5028 | Val Loss: 1.0918 | Val Acc: 0.5333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/150 -- Train Loss: 1.1709 | Train Acc: 0.5037 | Val Loss: 1.1111 | Val Acc: 0.5083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/150 -- Train Loss: 1.1829 | Train Acc: 0.4963 | Val Loss: 1.0985 | Val Acc: 0.5917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/150 -- Train Loss: 1.1756 | Train Acc: 0.4991 | Val Loss: 1.0716 | Val Acc: 0.5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/150 -- Train Loss: 1.1807 | Train Acc: 0.5074 | Val Loss: 1.0781 | Val Acc: 0.5417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/150 -- Train Loss: 1.1712 | Train Acc: 0.4981 | Val Loss: 1.0601 | Val Acc: 0.5417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/150 -- Train Loss: 1.1724 | Train Acc: 0.5028 | Val Loss: 1.0542 | Val Acc: 0.5667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/150 -- Train Loss: 1.1540 | Train Acc: 0.5083 | Val Loss: 1.0729 | Val Acc: 0.5917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/150 -- Train Loss: 1.1542 | Train Acc: 0.4898 | Val Loss: 1.0492 | Val Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/150 -- Train Loss: 1.1390 | Train Acc: 0.5222 | Val Loss: 1.0775 | Val Acc: 0.4833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/150 -- Train Loss: 1.1659 | Train Acc: 0.5046 | Val Loss: 1.0699 | Val Acc: 0.5917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/150 -- Train Loss: 1.1626 | Train Acc: 0.5148 | Val Loss: 1.0657 | Val Acc: 0.5750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/150 -- Train Loss: 1.1552 | Train Acc: 0.5306 | Val Loss: 1.0522 | Val Acc: 0.5583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/150 -- Train Loss: 1.1545 | Train Acc: 0.5028 | Val Loss: 1.0484 | Val Acc: 0.6167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/150 -- Train Loss: 1.1461 | Train Acc: 0.5204 | Val Loss: 1.0404 | Val Acc: 0.6167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/150 -- Train Loss: 1.1380 | Train Acc: 0.5352 | Val Loss: 1.0274 | Val Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150 -- Train Loss: 1.1344 | Train Acc: 0.5130 | Val Loss: 1.0241 | Val Acc: 0.5833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/150 -- Train Loss: 1.1331 | Train Acc: 0.5250 | Val Loss: 1.0182 | Val Acc: 0.6083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/150 -- Train Loss: 1.1370 | Train Acc: 0.5315 | Val Loss: 1.0388 | Val Acc: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/150 -- Train Loss: 1.1408 | Train Acc: 0.5296 | Val Loss: 1.0544 | Val Acc: 0.5333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/150 -- Train Loss: 1.1171 | Train Acc: 0.5370 | Val Loss: 1.0310 | Val Acc: 0.6083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/150 -- Train Loss: 1.1215 | Train Acc: 0.5148 | Val Loss: 1.0134 | Val Acc: 0.5833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/150 -- Train Loss: 1.1250 | Train Acc: 0.5241 | Val Loss: 1.0453 | Val Acc: 0.5583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/150 -- Train Loss: 1.1155 | Train Acc: 0.5287 | Val Loss: 1.0278 | Val Acc: 0.5833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/150 -- Train Loss: 1.1110 | Train Acc: 0.5361 | Val Loss: 1.0355 | Val Acc: 0.5667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/150 -- Train Loss: 1.1032 | Train Acc: 0.5324 | Val Loss: 1.0304 | Val Acc: 0.5833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/150 -- Train Loss: 1.1018 | Train Acc: 0.5287 | Val Loss: 1.0139 | Val Acc: 0.5917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/150 -- Train Loss: 1.1072 | Train Acc: 0.5306 | Val Loss: 1.0580 | Val Acc: 0.5833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/150 -- Train Loss: 1.0989 | Train Acc: 0.5343 | Val Loss: 1.0278 | Val Acc: 0.5750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/150 -- Train Loss: 1.0942 | Train Acc: 0.5417 | Val Loss: 1.0273 | Val Acc: 0.5667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/150 -- Train Loss: 1.0869 | Train Acc: 0.5435 | Val Loss: 1.0289 | Val Acc: 0.5833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/150 -- Train Loss: 1.0701 | Train Acc: 0.5463 | Val Loss: 1.0386 | Val Acc: 0.5750\n",
      "No improvement for 10 epochs. Stopping early.\n",
      "Best Validation Loss: 1.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/home/Documents/pytorch-test/env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.1928\n",
      "Accuracy  : 0.5450\n",
      "Precision : 0.3608\n",
      "Recall    : 0.3805\n",
      "F1 Score  : 0.3498\n",
      "-----------------------------------------------------\n",
      "\n",
      "======== Training on dataset: organcmnist ========\n",
      "Computed class weights for organcmnist: [0.84055843 1.54818509 1.59401952 1.61527311 0.89077561 0.82834519\n",
      " 0.32456928 0.96722941 0.94830124 0.82622666 0.61651646]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 -- Train Loss: 1.3687 | Train Acc: 0.5026 | Val Loss: 0.6505 | Val Acc: 0.7266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 -- Train Loss: 0.9123 | Train Acc: 0.6466 | Val Loss: 0.5740 | Val Acc: 0.7751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[246], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Train the model, monitoring validation loss\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m model \u001b[38;5;241m=\u001b[39m train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Once training is complete, evaluate on the test set\u001b[39;00m\n\u001b[1;32m     43\u001b[0m evaluate_model(model, test_loader, criterion, device)\n",
      "Cell \u001b[0;32mIn[243], line 42\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, patience)\u001b[0m\n\u001b[1;32m     39\u001b[0m train_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     41\u001b[0m train_pbar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Training\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (images, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_pbar):\n\u001b[1;32m     43\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     44\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Documents/pytorch-test/env/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/pytorch-test/env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m~/Documents/pytorch-test/env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Documents/pytorch-test/env/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/pytorch-test/env/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[58], line 47\u001b[0m, in \u001b[0;36mMyMedNISTDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     44\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(np\u001b[38;5;241m.\u001b[39muint8(image))\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m---> 47\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n",
      "File \u001b[0;32m~/Documents/pytorch-test/env/lib/python3.11/site-packages/torchvision/transforms/transforms.py:93\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     90\u001b[0m         _log_api_usage_once(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;241m=\u001b[39m transforms\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m     95\u001b[0m         img \u001b[38;5;241m=\u001b[39m t(img)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "for key in dataset_keys:\n",
    "    print(f\"======== Training on dataset: {key} ========\")\n",
    "    npz_path = f\"./data/{key}.npz\"\n",
    "    info = INFO[key]\n",
    "    n_channels = info.get('n_channels', 1)\n",
    "    # Get transforms. For this example, we assume images are single-channel.\n",
    "    train_transform, val_transform, test_transform = get_transforms(n_channels)\n",
    "    \n",
    "    # Create dataset splits\n",
    "    train_dataset = MyMedNISTDataset(npz_path=npz_path, split='train', transform=train_transform)\n",
    "    val_dataset   = MyMedNISTDataset(npz_path=npz_path, split='val', transform=val_transform)\n",
    "    test_dataset  = MyMedNISTDataset(npz_path=npz_path, split='test', transform=test_transform)\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Create a new instance of your model\n",
    "    # (Assuming the number of classes is task_classes[key])\n",
    "    model = MyCNN(num_classes=task_classes[key])\n",
    "    model = model.to(device)\n",
    "    \n",
    "    train_labels = train_dataset.labels  \n",
    "    unique, counts = np.unique(train_labels, return_counts=True)\n",
    "    # Inverse frequency weights:\n",
    "    weights = 1.0 / counts\n",
    "    # Normalize weights such that the average weight is 1.\n",
    "    weights = weights / weights.mean()\n",
    "    print(f\"Computed class weights for {key}: {weights}\")\n",
    "    # Create a task-specific loss criterion.\n",
    "    criterion_task = torch.nn.CrossEntropyLoss(weight=torch.tensor(weights, dtype=torch.float).to(device))\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    \n",
    "    # Train the model, monitoring validation loss\n",
    "    model = train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=num_epochs)\n",
    "    \n",
    "    # Once training is complete, evaluate on the test set\n",
    "    evaluate_model(model, test_loader, criterion, device)\n",
    "    \n",
    "    # Free up memory for the next dataset\n",
    "    del model, train_dataset, val_dataset, test_dataset, train_loader, val_loader, test_loader\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"-----------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, feat_dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(feat_dim)\n",
    "        self.linear1 = nn.Linear(feat_dim, feat_dim * 4)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear2 = nn.Linear(feat_dim * 4, feat_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # Save input for the skip connection.\n",
    "        out = self.layer_norm(x)\n",
    "        out = self.linear1(out)\n",
    "        out = self.gelu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear2(out)\n",
    "        return residual + out  # Skip connection.\n",
    "\n",
    "class MultiTaskResNet(nn.Module):\n",
    "    def __init__(self, task_outputs, backbone='resnet18', pretrained=True, bw=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            task_outputs (dict): Mapping from task names to number of output classes.\n",
    "                                 e.g. {\"breastmnist\": 2, \"dermamnist\": 7, ...}\n",
    "            backbone (str): Which ResNet to use ('resnet18' or 'resnet50').\n",
    "            pretrained (bool): If True, load pretrained weights.\n",
    "        \"\"\"\n",
    "        super(MultiTaskResNet, self).__init__()\n",
    "        \n",
    "        # Load the chosen ResNet backbone.\n",
    "        if backbone == 'resnet18':\n",
    "            resnet = models.resnet18(pretrained=pretrained)\n",
    "            self.feat_dim = 512\n",
    "        elif backbone == 'resnet34':\n",
    "            resnet = models.resnet34(pretrained=pretrained)\n",
    "            self.feat_dim = 512\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported backbone\")\n",
    "        \n",
    "        # Modify the input layer for 3x28x28 images:\n",
    "        # Change conv1: use kernel_size=3, stride=1, padding=1.\n",
    "        if bw:\n",
    "            resnet.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        else:\n",
    "            resnet.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        # Replace maxpool with identity to avoid aggressive downsampling.\n",
    "        resnet.maxpool = nn.Identity()\n",
    "        \n",
    "        # Remove the final fully connected layer.\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])  # Output shape: (B, feat_dim, 1, 1)\n",
    "        \n",
    "        # Freeze all backbone parameters.\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Unfreeze only the last two blocks: layer3 and layer4.\n",
    "        # For ResNet-18, children order is: conv1, bn1, relu, maxpool, layer1, layer2, layer3, layer4, avgpool.\n",
    "        # We unfreeze last 2 layers\n",
    "        for child in list(self.backbone.children())[-6:]:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "        # also unfreeze the first layer as we changed it and needs to be trained\n",
    "        for child in list(self.backbone.children())[0:1]:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        # Define task-specific MLP heads.\n",
    "        self.task_outputs = task_outputs\n",
    "        self.heads = nn.ModuleDict({\n",
    "            task: nn.Sequential(\n",
    "                # First, apply a LayerNorm to the features.\n",
    "                nn.LayerNorm(self.feat_dim),\n",
    "                \n",
    "                # First block with an attention-like mechanism (including a squeeze-and-excitation sub-block).\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(self.feat_dim, self.feat_dim),\n",
    "                    nn.GELU(),\n",
    "                    nn.Dropout(0.2),\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(self.feat_dim, self.feat_dim // 4),\n",
    "                        nn.GELU(),\n",
    "                        nn.Linear(self.feat_dim // 4, self.feat_dim),\n",
    "                        nn.Sigmoid()\n",
    "                    )\n",
    "                ),\n",
    "                \n",
    "                # Second block using our ResidualBlock.\n",
    "                ResidualBlock(self.feat_dim),\n",
    "                \n",
    "                # Final classification block.\n",
    "                nn.Sequential(\n",
    "                    nn.LayerNorm(self.feat_dim),\n",
    "                    nn.Linear(self.feat_dim, num_classes)\n",
    "                )\n",
    "            ) for task, num_classes in self.task_outputs.items()\n",
    "        })\n",
    "    \n",
    "    def forward(self, x, task):\n",
    "        # Extract features with the frozen backbone.\n",
    "        features = self.backbone(x)               # (B, feat_dim, 1, 1)\n",
    "        features = features.view(features.size(0), -1)  # Flatten to (B, feat_dim)\n",
    "        if task not in self.heads:\n",
    "            raise ValueError(f\"Task '{task}' not found. Available tasks: {list(self.heads.keys())}\")\n",
    "        out = self.heads[task](features)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, criterion, task, scheduler, max_epochs=7, patience=2, device='cpu'):\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # If labels come in as [B, 1], squeeze only dimension 1.\n",
    "            if labels.dim() == 2:\n",
    "                labels = labels.squeeze(1)\n",
    "            if labels.numel() == 0:\n",
    "                continue\n",
    "            labels = labels.long()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, task=task)\n",
    "            if outputs.size(0) != labels.size(0):\n",
    "                continue\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_loss = running_loss / total if total > 0 else 0\n",
    "        train_acc = correct / total if total > 0 else 0\n",
    "        print(f\"Task: {task} | Epoch [{epoch+1}/{max_epochs}] | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "        \n",
    "        # Step the learning rate scheduler at the end of each epoch.\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_metrics = evaluate_model(model, val_loader, criterion, task, device=device, mode='val')\n",
    "        val_loss = val_metrics[\"avg_loss\"]\n",
    "        \n",
    "        print(f\"Task: {task} | Epoch [{epoch+1}/{max_epochs}] | Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Early stopping check.\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            best_model_state = model.state_dict()\n",
    "        elif epoch - best_epoch >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}. Best val loss: {best_val_loss:.4f}\")\n",
    "            break\n",
    "\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, fbeta_score\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, task, device='cpu', mode='test'):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            if labels.dim() == 2:\n",
    "                labels = labels.squeeze(1)\n",
    "            if labels.numel() == 0:\n",
    "                continue\n",
    "            labels = labels.long()\n",
    "            \n",
    "            outputs = model(images, task=task)\n",
    "            if outputs.size(0) != labels.size(0):\n",
    "                continue\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    avg_loss = running_loss / total if total > 0 else 0\n",
    "    accuracy_val = correct / total if total > 0 else 0\n",
    "    macro_f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0) if total > 0 else 0\n",
    "    macro_f2 = fbeta_score(all_labels, all_preds, beta=2, average='macro', zero_division=0) if total > 0 else 0\n",
    "    if mode=='test':\n",
    "        print(f\"\\n{mode.upper()} Metrics for task '{task}':\")\n",
    "        print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "        print(f\"Accuracy: {accuracy_val:.4f}\")\n",
    "        print(f\"Macro F1 Score: {macro_f1:.4f}\")\n",
    "        print(f\"Macro F2 Score: {macro_f2:.4f}\")\n",
    "    \n",
    "    return {\"avg_loss\": avg_loss, \"accuracy\": accuracy_val, \"macro_f1\": macro_f1, \"macro_f2\": macro_f2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# List of dataset keys.\n",
    "dataset_keys = [\n",
    "    'breastmnist',\n",
    "    'dermamnist',\n",
    "    'octmnist',\n",
    "    'organamnist',\n",
    "    'organcmnist',\n",
    "    'organsmnist',\n",
    "    'pathmnist',\n",
    "    'pneumoniamnist',\n",
    "    'retinamnist',\n",
    "    'tissuemnist',\n",
    "    'bloodmnist'\n",
    "]\n",
    "\n",
    "def get_transforms(n_channels):\n",
    "    # If not 3 channels, first convert to 3 channels; otherwise, use identity.\n",
    "    convert = transforms.Grayscale(num_output_channels=3) if n_channels != 3 else lambda x: x\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        convert,\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.1),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.1),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                             std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        convert,\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                             std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    val_transform = test_transform\n",
    "\n",
    "    return train_transform, val_transform, test_transform\n",
    "\n",
    "# Assume task_classes is defined for all tasks.\n",
    "\n",
    "task_classes = {'breastmnist': 2,\n",
    " 'dermamnist': 7,\n",
    " 'octmnist': 4,\n",
    " 'organamnist': 11,\n",
    " 'organcmnist': 11,\n",
    " 'organsmnist': 11,\n",
    " 'pathmnist': 9,\n",
    " 'pneumoniamnist': 2,\n",
    " 'retinamnist': 5,\n",
    " 'tissuemnist': 8,\n",
    " 'bloodmnist': 8}\n",
    "\n",
    "max_epochs = {\n",
    "    'breastmnist': 100,\n",
    "    'dermamnist': 100,\n",
    "    'octmnist': 10,\n",
    "    'organamnist': 50,\n",
    "    'organcmnist': 50,\n",
    "    'organsmnist': 25,\n",
    "    'pathmnist': 10,\n",
    "    'pneumoniamnist': 100,\n",
    "    'retinamnist': 100,\n",
    "    'tissuemnist': 10,\n",
    "    'bloodmnist': 100\n",
    "}\n",
    "\n",
    "# Set device.\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Instantiate the multi-task model using CLIP Vit B/32 as backbone.\n",
    "# For this example, we assume a MultiTaskCLIP model exists.\n",
    "# If not, you can modify the MultiTaskResNet model to load CLIP instead.\n",
    "# For demonstration, I'll assume you have a model similar to MultiTaskCLIP defined.\n",
    "# Here, we'll use MultiTaskResNet as a placeholder.\n",
    "model = MultiTaskResNet(task_outputs=task_classes, backbone='resnet34', pretrained=True).to(device)\n",
    "# (Replace above with your MultiTaskCLIP model if available.)\n",
    "\n",
    "# Define optimizer and loss.\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Add a learning rate scheduler (CosineAnnealingLR)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Task: BREASTMNIST ===\n",
      "Loaded breastmnist dataset. Train: 546, Val: 78, Test: 156\n",
      "Computed class weights for breastmnist: [1.46153846 0.53846154]\n",
      "Task: breastmnist | Epoch [1/100] | Train Loss: 1.9771 | Train Acc: 0.5348\n",
      "Task: breastmnist | Epoch [1/100] | Val Loss: 0.9845\n",
      "Task: breastmnist | Epoch [2/100] | Train Loss: 0.7281 | Train Acc: 0.5458\n",
      "Task: breastmnist | Epoch [2/100] | Val Loss: 0.6794\n",
      "Task: breastmnist | Epoch [3/100] | Train Loss: 0.6522 | Train Acc: 0.5604\n",
      "Task: breastmnist | Epoch [3/100] | Val Loss: 0.6422\n",
      "Task: breastmnist | Epoch [4/100] | Train Loss: 0.5834 | Train Acc: 0.7344\n",
      "Task: breastmnist | Epoch [4/100] | Val Loss: 1.1402\n",
      "Task: breastmnist | Epoch [5/100] | Train Loss: 0.5695 | Train Acc: 0.7399\n",
      "Task: breastmnist | Epoch [5/100] | Val Loss: 0.6164\n",
      "Task: breastmnist | Epoch [6/100] | Train Loss: 0.5203 | Train Acc: 0.7875\n",
      "Task: breastmnist | Epoch [6/100] | Val Loss: 0.5156\n",
      "Task: breastmnist | Epoch [7/100] | Train Loss: 0.5048 | Train Acc: 0.7821\n",
      "Task: breastmnist | Epoch [7/100] | Val Loss: 1.0723\n",
      "Task: breastmnist | Epoch [8/100] | Train Loss: 0.5289 | Train Acc: 0.7491\n",
      "Task: breastmnist | Epoch [8/100] | Val Loss: 0.4287\n",
      "Task: breastmnist | Epoch [9/100] | Train Loss: 0.5119 | Train Acc: 0.7674\n",
      "Task: breastmnist | Epoch [9/100] | Val Loss: 0.4384\n",
      "Task: breastmnist | Epoch [10/100] | Train Loss: 0.4727 | Train Acc: 0.7582\n",
      "Task: breastmnist | Epoch [10/100] | Val Loss: 0.5308\n",
      "Task: breastmnist | Epoch [11/100] | Train Loss: 0.5091 | Train Acc: 0.8187\n",
      "Task: breastmnist | Epoch [11/100] | Val Loss: 0.4615\n",
      "Task: breastmnist | Epoch [12/100] | Train Loss: 0.5037 | Train Acc: 0.7527\n",
      "Task: breastmnist | Epoch [12/100] | Val Loss: 0.8463\n",
      "Task: breastmnist | Epoch [13/100] | Train Loss: 0.4853 | Train Acc: 0.7802\n",
      "Task: breastmnist | Epoch [13/100] | Val Loss: 0.7276\n",
      "Task: breastmnist | Epoch [14/100] | Train Loss: 0.4570 | Train Acc: 0.7930\n",
      "Task: breastmnist | Epoch [14/100] | Val Loss: 0.6694\n",
      "Task: breastmnist | Epoch [15/100] | Train Loss: 0.4747 | Train Acc: 0.8077\n",
      "Task: breastmnist | Epoch [15/100] | Val Loss: 0.5958\n",
      "Task: breastmnist | Epoch [16/100] | Train Loss: 0.4639 | Train Acc: 0.8004\n",
      "Task: breastmnist | Epoch [16/100] | Val Loss: 0.5771\n",
      "Task: breastmnist | Epoch [17/100] | Train Loss: 0.4202 | Train Acc: 0.8278\n",
      "Task: breastmnist | Epoch [17/100] | Val Loss: 0.4935\n",
      "Task: breastmnist | Epoch [18/100] | Train Loss: 0.4266 | Train Acc: 0.8095\n",
      "Task: breastmnist | Epoch [18/100] | Val Loss: 0.5734\n",
      "Early stopping triggered at epoch 18. Best val loss: 0.4287\n",
      "\n",
      "TEST Metrics for task 'breastmnist':\n",
      "Average Loss: 0.5553\n",
      "Accuracy: 0.8205\n",
      "Macro F1 Score: 0.7421\n",
      "Macro F2 Score: 0.7259\n",
      "\n",
      "=== Processing Task: DERMAMNIST ===\n",
      "Loaded dermamnist dataset. Train: 7007, Val: 1003, Test: 2005\n",
      "Computed class weights for dermamnist: [0.94264888 0.59867394 0.27948497 2.68654932 0.27589723 0.04579671\n",
      " 2.17094894]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[156], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m criterion_task \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(weight\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(weights, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Train on this task using early stopping.\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m model \u001b[38;5;241m=\u001b[39m train_model(model, loader_train, loader_val, optimizer, criterion_task, key, scheduler, max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs[key], patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m metrics \u001b[38;5;241m=\u001b[39m evaluate_model(model, loader_test, criterion_task, task\u001b[38;5;241m=\u001b[39mkey, device\u001b[38;5;241m=\u001b[39mdevice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[146], line 31\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, task, scheduler, max_epochs, patience, device)\u001b[0m\n\u001b[1;32m     28\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 31\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     32\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     33\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import time\n",
    "\n",
    "results = {}\n",
    "\n",
    "for key in dataset_keys:\n",
    "    \n",
    "        print(f\"\\n=== Processing Task: {key.upper()} ===\")\n",
    "        info = INFO[key]\n",
    "        n_channels = info.get('n_channels', 1)\n",
    "        train_transform, val_transform, test_transform = get_transforms(n_channels)\n",
    "        # if(n_channels == 1):\n",
    "        #         bw = True\n",
    "        # else:\n",
    "        #         bw = False\n",
    "        \n",
    "        npz_path = f\"./data/{key}.npz\"\n",
    "        # Load the train, validation, and test splits using mmap_mode to save RAM.\n",
    "        ds_train = MyMedNISTDataset(npz_path=npz_path, split='train', transform=train_transform)\n",
    "        ds_val   = MyMedNISTDataset(npz_path=npz_path, split='val', transform=val_transform)\n",
    "        ds_test  = MyMedNISTDataset(npz_path=npz_path, split='test', transform=test_transform)\n",
    "    \n",
    "        print(f\"Loaded {key} dataset. Train: {len(ds_train)}, Val: {len(ds_val)}, Test: {len(ds_test)}\")\n",
    "    \n",
    "        # Create DataLoaders (you can adjust batch_size if needed).\n",
    "        loader_train = DataLoader(ds_train, batch_size=64, shuffle=True, num_workers=0)\n",
    "        loader_val   = DataLoader(ds_val, batch_size=64, shuffle=False, num_workers=0)\n",
    "        loader_test  = DataLoader(ds_test, batch_size=64, shuffle=False, num_workers=0)\n",
    "        \n",
    "        # Compute class weights from training labels.\n",
    "        # (Assuming ds_train.labels returns an array-like object of labels.)\n",
    "        train_labels = ds_train.labels  \n",
    "        unique, counts = np.unique(train_labels, return_counts=True)\n",
    "        # Inverse frequency weights:\n",
    "        weights = 1.0 / counts\n",
    "        # Normalize weights such that the average weight is 1.\n",
    "        weights = weights / weights.mean()\n",
    "        print(f\"Computed class weights for {key}: {weights}\")\n",
    "        # Create a task-specific loss criterion.\n",
    "        criterion_task = torch.nn.CrossEntropyLoss(weight=torch.tensor(weights, dtype=torch.float).to(device))\n",
    "        \n",
    "        # Train on this task using early stopping.\n",
    "        model = train_model(model, loader_train, loader_val, optimizer, criterion_task, key, scheduler, max_epochs=max_epochs[key], patience=10, device=device)\n",
    "        \n",
    "        # Evaluate the model on the test set.\n",
    "        metrics = evaluate_model(model, loader_test, criterion_task, task=key, device=device, mode='test')\n",
    "        results[key] = metrics\n",
    "        \n",
    "        torch.save(model.state_dict(), f\"{key}_{metrics['macro_f1']}.pth\")\n",
    "    \n",
    "        del ds_train, ds_val, ds_test, loader_train, loader_val, loader_test\n",
    "        \n",
    "        \n",
    "        gc.collect()\n",
    "        time.sleep(1)  # Sleep for 1 second to allow memory to free up.\n",
    "\n",
    "# Print overall evaluation metrics for each task.\n",
    "print(\"\\n=== Overall Evaluation Metrics ===\")\n",
    "for key, metrics in results.items():\n",
    "    print(f\"{key.upper()} -> Loss: {metrics['avg_loss']:.4f}, Accuracy: {metrics['accuracy']:.4f}, Macro F1: {metrics['macro_f1']:.4f}, Macro F2: {metrics['macro_f2']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
